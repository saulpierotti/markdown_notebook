<h1 id="introduction">Introduction</h1>
<ul>
<li>Phylogenetic methods apply to both DNA and protein, but we will focus mostly on DNA since it is easier to work with</li>
<li>We want to compare samples in order to understand their coancestry</li>
<li>Individuals do not evolve, populations do</li>
<li>The specific name is not univocus, we need also to specify the genus</li>
<li>The species is the only natural classification, higher classifications are human-made</li>
<li>Darwin’s postulates of evolution: populations change over time
<ul>
<li>Individuals in a species have a certain variability</li>
<li>Some variation is heritable</li>
<li>Survival and reproduction are not completely random</li>
</ul></li>
<li>Evolution is more like a brancking tree than a ladder</li>
<li>Evolution involves first mutation and then selection</li>
<li>Selection can be of different types
<ul>
<li>Stabilizing, if it tends to increase the frequency of an optimal trait</li>
<li>Directional, if a trait becomes more and more extreme</li>
<li>Disruptive, if it tends to go away from a certain trait</li>
<li>Balancing, if all traits are equally favored</li>
</ul></li>
<li>Other than selection, evolution is promoted by genetic drift
<ul>
<li>The effect is stronger in small populations</li>
</ul></li>
<li>The effective population size is the size of an ideal population with random mating that has the same gene frequency changes as the studied population (the census)</li>
<li>Two lineages that, going back in time merge in a single ancestor define a coalescent event
<ul>
<li>The mrca of all the individuals in a population almost never dates back to the first generation</li>
<li>The colaescent time of a population is the time passed since the mrca of all individuals existed</li>
</ul></li>
<li>Deterministic evolution is possible only in infinite popualtions: real models are stochastic and we can only predict the probabilities of allele frequencies</li>
<li>An operational taxonomic unit is one of the leaves of the tree (OTU)
<ul>
<li>It is a proxy for the species concept in organisms without clear species boundaries</li>
</ul></li>
<li>A group of taxa that share the same branch is a monophiletic cluster</li>
<li>The topology of a tree is its branching pattern</li>
<li>Nodes of the tree are hypothetical taxonomic units (HTU)</li>
<li>The lenght of edges is related to divergence time</li>
<li>Trees can be rooted by using an outgroup
<ul>
<li>The outgrup is by itself an OTU which is for sure more distant to all the other OTUs than the distance among OTUs</li>
<li>All the OTUs but the outgrup represent the ingroup</li>
<li>The root of the tree is the node connecting the outgroup and the ingroup</li>
</ul></li>
<li>If an outgroup is not available, a tree can be rooted by midpoint rooting
<ul>
<li>The root is the node connecting the most distantly related OTUs</li>
</ul></li>
<li>A monophyletic group is a clade that includes the most recent common ancestor of all the leaves and all the descendant of that ancestor
<ul>
<li>A clade is always monophyletic</li>
</ul></li>
<li>LUCA: life is thought to be monophiletic</li>
<li>A paraphyletic group includes the most recent common ancestor of all the leaves, but not all the leaves of that ancestor</li>
<li>A poliphyletic group includes leaves from more than 1 taxon</li>
<li>Evolution is like a branching tree, not like a ladder
<ul>
<li>What is commonly considered ancestor is a sister group, the real ancestor does not exist any more!</li>
</ul></li>
<li>The observed genetic distance between 2 species is the sum of the distance between both species and their common ancestor</li>
<li>The more distant the split, the more the genetic distance</li>
<li>Frequency of observed mutation is inversely related to the strenght of selective pressure
<ul>
<li>Low mutation rate can be related to higher gene content</li>
<li>When selecting a region for phylogenetic analysis, we need to adjust the mutation rate with the distance between the OTUs
<ul>
<li>I cannot use very divergent regions for distantly related organisms or very conserved regions for closely related organisms!</li>
</ul></li>
<li>Differential mutation rate can be observed also inside genes</li>
</ul></li>
<li>The rate of synonimus (S) and non-synonimus (N) mutation is an indication of the selection regime
<ul>
<li>S &gt; N suggests positive selection</li>
<li>S = N suggests neutral selection</li>
<li>S less than N suggests negative selection</li>
</ul></li>
<li>The neutral theory of molecular evolution (Kimura) states that most molecular divergence is neutral
<ul>
<li>In most populations the effective population size is incredibly small compared to the magnitude of the selective forces</li>
<li>Most fixation events are the result of stochastic process on quasi-neutral mutations</li>
<li>Adaptive evolution is more predominant when the species is far from the peaks of the fitness landscape</li>
</ul></li>
<li>Speciation is favored by events that reduce the diversity of a population while increasing the diversity with other populations</li>
<li>The probability of fixation due to genetic drift of a mutation is equal to its frequency
<ul>
<li>If n is the popualtion size, in a diploid population a new mutation has a frequency of 1/2n</li>
<li>On average, it takes 4n generation to fix a mutation through drift</li>
</ul></li>
</ul>
<h1 id="phylogenetic-markers-and-trees">Phylogenetic markers and trees</h1>
<ul>
<li>Initially classification was based on morphological carachters, and taxonomy is still largely based on this
<ul>
<li>Today we tend to use much more molecular data such as DNA and protein sequences, and RFLPs</li>
<li>The prefereability of molecular or morphological data is under debeate (Patterson et al, 1993)</li>
<li>For estinct species, we often don’t have molecular data</li>
</ul></li>
<li>Initially the molecular classification was based on allozymes, then RFLPs became prominent and now microsatellites, SNPs and sequencing data are most used</li>
<li>The variability of sequences arises from mutations, duplications, recombination, HGT
<ul>
<li>Point mutations, insertions and deletions are the most used data for molecular phylogenetics</li>
</ul></li>
<li>Molecular phylogenetics studies the similarities of 2 sequences assuming that they are homologous</li>
<li>Most variability in homologous sequences arises from point mutations in the 3rd codon position</li>
<li>Different genes or portions of gene can have different conservation rates, and distantly related homologs can be identified only in enzymes and structural proteins
<ul>
<li>In introns usually the divergence rate is that derived from neutral evolution, while in exons it is higher or lower</li>
<li>When not even sequence of core regions are conserved, homology can be detected at the structural level</li>
<li>Closely related species can be compared at the DNA level, families and genera are better compared at the aminoacid level</li>
</ul></li>
<li>The level of variability is not constant for all organisms and species
<ul>
<li>Citochrome B is really variable in insects but not in mammals</li>
<li>Cytochrome C is more variable in mammals</li>
<li>Before doing something on a gene look at the literature!</li>
</ul></li>
<li>Paralogous genes derive from duplication, orthologous genes from speciation
<ul>
<li>Studing paralogous sequences is informative for the duplication event</li>
<li>Orthologous sequences are informative for speciation events</li>
<li>If I want to study speciation I need to be sure that my locus is orthologous!</li>
</ul></li>
<li>When we compare sequences or characters they must be homologous!</li>
<li>Homologus genes need to be orthologus in order to be useful for classification</li>
<li>Multiple substitutions on the same site or equal substitutions in different species can lead to underestimate the genetic distance: homoplasy</li>
<li>The molecular clock hypothesis assumes constant mutation rate
<ul>
<li>Implicitely it assumes neutral evolution!</li>
<li>Double molecular distance means double separation time</li>
</ul></li>
<li>The mtDNA is smaller, aploid and more variable than the nuclear genome
<ul>
<li>It is some orders of magnitude more variable than the nDNA!
<ul>
<li>Less efficient proofreading</li>
<li>Many more replications per individual</li>
</ul></li>
<li>mtDNA is useful for analysing shallow divergence</li>
<li>It tells only about the maternal lineage!</li>
</ul></li>
<li>Nucelar DNA is less variable, subject to recombination, polyploid: a mess!</li>
<li>Gene rearrangments are really unlikely to happen twice in the same way
<ul>
<li>Therefore, they are relly good to establish relationships</li>
<li>The insertion of transposable sequences is one of these</li>
</ul></li>
<li>Transcriptome sequencing is better than DNA sequencing in many cases
<ul>
<li>It is easier to assemble and annotate</li>
<li>It is easier to handle since it is smaller</li>
</ul></li>
<li>Recombination events can create incoherent trees for the same species
<ul>
<li>In this case It is more adequate to represent the phylogeny with a network, not a tree</li>
</ul></li>
<li>For phylogenetic analysis, we aim at using loci under neutral selection</li>
<li>To understand the significance of a phylogenetic hypotesis we can use other information from biogeography</li>
<li>Relations determined by genes under strong selection can give wrong results!
<ul>
<li>Convergent evolution can make me cluster unrelated species, while splitting related species that have adapted to new environments</li>
</ul></li>
<li>In some instances tree can be not binary: politomy
<ul>
<li>Hard politomy refers to multiple, almost simultaneous speciation from a single ancestor
<ul>
<li>Its existence is not clear, but it seems to be approximated by explosive radiation events in viruses</li>
</ul></li>
<li>Soft politomy refers to uncertainty in a given topology</li>
</ul></li>
<li>A species cannot be represented by a single DNA sequence</li>
<li>When we create a tree we actually reconstruct the phylogeny of the marker, not of the species</li>
<li>Because of this, we want to use many molecular markers at the same time</li>
<li>We want to find which gene trees are informative for and overlap with the the species tree
<ul>
<li>If the genes that I am studying are paralogous, the coalescent event for the gene will be different than for the species!</li>
</ul></li>
<li>Higher coalescence time is related to lower probability of wrong trees</li>
<li>The probability of coalescence for a pair of genes in 1 generation is 1/2N, where N is the size of a diploid population
<ul>
<li>It is the probability that 2 copy of a gene derive from the same parent gene in the previous generation</li>
</ul></li>
<li>It assumes (Kingman’s assumptions) a panmittic population, neutral evolution, infinite sites and non-overlapping populations
<ul>
<li>In a panmittic population there is no preferential mating</li>
</ul></li>
<li>The probability that the gene tree and the species tree don’t overlap is  <img class="inlinemath" src="eqn000.png" WIDTH=35 HEIGHT=26 STYLE="vertical-align: -7px; margin: 0;" alt="\frac{2}{3}e^{\frac{-t}{2N}}" /> <ul>
<li>This derives from the probability of coalescence</li>
<li>Whith more than 6 genes the probability of a wrong tree is significantly reduced</li>
</ul></li>
<li>Incomplete lineage sorting is the non-overlapping of gene and species tree
<ul>
<li>Its probability is directly proportional with the ploidy of the species and inversely proportional with the number of generations since the split and with the number of genes under analysis</li>
</ul></li>
</ul>
<h1 id="multiple-sequence-alignments">Multiple sequence alignments</h1>
<ul>
<li>A multiple sequence alignment (MSA) is an hypothesis about the homology of multiple sequences
<ul>
<li>We arrange sequences so to have homologous positions in the same column</li>
</ul></li>
<li>In order to find the real alignment of 2 sequences, I need to know the sequence of the mrca!</li>
<li>A simple model for aligning DNA: +1 for matches and -1 for mismatches</li>
<li>Modelling gaps: we can use different penalties for opening and extending a gap</li>
<li>Weighted sum of pairs: WSP objective function
<ul>
<li>It is a simple way to score MSAs</li>
<li>For each position, I get the pairwise score of each pair and I sum it</li>
<li>I can use a weight for each score that balances the over-representation of some sequences</li>
</ul></li>
<li>We could use dynamic programming on a multi-dimensional matrix for maximizing the WSP function, but this requires  <img class="inlinemath" src="eqn001.png" WIDTH=55 HEIGHT=21 STYLE="vertical-align: -5px; margin: 0;" alt="O(N^M)" /> time<ul>
<li>N is the sequence lenght and M the number of sequences</li>
<li>It is practically impossible for more than 4 sequences</li>
</ul></li>
<li>Progressive alignment methods are fast but sub-optimal
<ul>
<li>They build a tree and use the tree for guiding the alignment
<ul>
<li>Usually the tree is built with NJ</li>
</ul></li>
<li>They are by far the most used MSA approaches</li>
<li>Once I have the tree, it procedes by pairwise alignment on the most related OTUs and progressively collapses the nodes</li>
<li>ClustalX and ClustalW belong to this category
<ul>
<li>ClustalW is textual while ClustalX is GUI</li>
<li>ClustalW automatically corrects for over-represented sequences</li>
</ul></li>
<li>Progressive alignment has a local minimum problem: early errors in the first alignments cannot be corrected later</li>
</ul></li>
<li>Consistency-base MSA: WSP scoring and intermediate sequence information used to improve pairwise alignments
<ul>
<li>T-Coffe is slower than ClustalX, but more accurate
<ul>
<li>It finds the MSA that most agrees with the pairwise alignments</li>
</ul></li>
</ul></li>
<li>Iterative approach: the alignment is refined in iteration steps until I reach the maximum possible score
<ul>
<li>It is faster and more effective than the progressive alignment</li>
<li>I create a guide tree using a raw distance matrix</li>
<li>This is the framework use by MUSCLE and MAFFT</li>
</ul></li>
<li>Strucutral methods use information about the RNA or protein strucuture
<ul>
<li>A loop can be of variable lenght, but a domain is more constrained</li>
</ul></li>
<li>In many cases (well-behaving datasets) the different alignment approaches give the same result, but there can be subtle differences</li>
<li>In difficult cases the result can be quite different</li>
<li>These methods employ a random seed: the same analysis can give slightly different results</li>
</ul>
<h1 id="distance-matrices">Distance matrices</h1>
<ul>
<li>The distance among sequences can be estimated from the number of observed substitutions
<ul>
<li>This is called observed distance or p-distance</li>
<li>I cannot observe multiple substitutions, so I tend to underestimate the distance!</li>
<li>We say that the p-distance saturates with respect to the true distance d when d gets high</li>
<li>From now, we will refer to true distance with d and observed distance with p</li>
</ul></li>
<li>The number of mutation expected in a given amount of time can be modelled by a Poisson distribution</li>
<li>This Poisson process can be described by a Markov chain
<ul>
<li>I can describe the Markov chain with a matrix Q of transition probabilities</li>
</ul></li>
<li>The transition probability of X to Y  <img class="inlinemath" src="eqn002.png" WIDTH=33 HEIGHT=14 STYLE="vertical-align: -5px; margin: 0;" alt="a_{X,Y}" /> is composed of the product of different terms<ul>
<li> <img class="inlinemath" src="eqn003.png" WIDTH=200 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(X -&gt; Y) = \mu * \pi_X * a_{X,Y}" /></li><li> <img class="inlinemath" src="eqn004.png" WIDTH=12 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\mu" /> is the mean substitution rate</li><li> <img class="inlinemath" src="eqn005.png" WIDTH=22 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\pi_X" /> is the relative abundance of the state X</li><li> <img class="inlinemath" src="eqn002.png" WIDTH=33 HEIGHT=14 STYLE="vertical-align: -5px; margin: 0;" alt="a_{X,Y}" /> is the relative mutation rate of X into Y compared to the other possible mutations</li><li>The self-transition probabilities are choosen so to make the sum of outgoing transitions from each state equal to 1</li>
</ul></li>
<li>Note the assumptions we are making
<ul>
<li>Mutations probablities are only dependent on the immediately preceding state (Markov property)</li>
<li>Substitution rates are constant in time (homogeneity)</li>
<li>The nucleotide frequencies are at equilibrium (stationariety)</li>
<li>These assumptions are not necessarily biologically reasonable, be careful!</li>
</ul></li>
<li>It is possible to develop time-reversible and non-time-reversible substitution models
<ul>
<li>In a time reversible model  <img class="inlinemath" src="eqn006.png" WIDTH=190 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(X -&gt; Y) = p(Y -&gt; X)" />, so their matrices are symmetric</li><li>We will only treat time-reversible models</li>
</ul></li>
<li>Given any Q matrix, it is possible to compute the probability of change for any evolutionary time t as exponential of the matrix
<ul>
<li> <img class="inlinemath" src="eqn007.png" WIDTH=68 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(t) = Q^t" /></li></ul></li>
<li>The Q matrix has 8 degrees of freedom
<ul>
<li>I have 6 possible relative mutation rates
<ul>
<li>These are the mutation rates Saul, not the transition probabilities!</li>
</ul></li>
<li>I have 4 possible nucleotide frequencies</li>
<li>The 2 groups have to sum up to 1, so I loose 2 degrees of freedom</li>
<li> <img class="inlinemath" src="eqn008.png" WIDTH=134 HEIGHT=19 STYLE="vertical-align: -4px; margin: 0;" alt="df = 6+4-2 = 8" /></li></ul></li>
<li>There are many models that specify a different number of parameters
<ul>
<li>Jukes Cantor (JK69) does not specify any parameter (0 parameters)
<ul>
<li>It assumes equal nucleotide frequencies,  <img class="inlinemath" src="eqn009.png" WIDTH=62 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="\pi=0.25" /></li><li>Substitution rates are all equal</li>
</ul></li>
<li>Kimura 2 parameter (KM) uses equal values for the substitutions,  <img class="inlinemath" src="eqn010.png" WIDTH=70 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="\pi s = 0.25" />, but models transitions and transversions</li><li>HKY85 is like the KM but it accounts for different nucleotide frequencies</li>
<li>TN models purine transition, pyrimidine transition and general transversion (5 parameters), plus different nucleotide frequencies</li>
<li>The general time reversible model (GTR) specifies all the parameters (8 parameters)</li>
</ul></li>
<li>More parameters are not always better, I risk to do overparametrization!
<ul>
<li>This is true when the exact value for the parameters is unknown</li>
</ul></li>
<li>The strenght of a phylogenetic signal decrease with time since it is more probable to have multiple substitutions
<ul>
<li>The plot of observed mutation with respect to distance tends to saturate</li>
</ul></li>
<li>Among-site variation: mutation rate among different position can vary
<ul>
<li>An example: the third codon position mutates faster than the first, that in turn mutates faster than the second</li>
<li>In general, different positions are snjected to different evolutionary forces</li>
</ul></li>
<li>We can model the among-site variation with the gamma distribution with expectation 1 and variance 1/ <img class="inlinemath" src="eqn011.png" WIDTH=12 HEIGHT=10 STYLE="vertical-align: -1px; margin: 0;" alt="\alpha" /> <ul>
<li>The modelled variable r is the relative mutation rate among sites, and its average is of course 1</li>
<li> <img class="inlinemath" src="eqn012.png" WIDTH=193 HEIGHT=21 STYLE="vertical-align: -5px; margin: 0;" alt="Pdf(r) = \alpha^\alpha r^{\alpha-1}/e^{-\alpha r}\Gamma(\alpha)" /></li><li>The shape parameter of the gamma distribution is called  <img class="inlinemath" src="eqn011.png" WIDTH=12 HEIGHT=10 STYLE="vertical-align: -1px; margin: 0;" alt="\alpha" /> , while when included in a Markov model it is called  <img class="inlinemath" src="eqn013.png" WIDTH=11 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\gamma" /> because of the distribution</li><li>By adjusting the parameter  <img class="inlinemath" src="eqn011.png" WIDTH=12 HEIGHT=10 STYLE="vertical-align: -1px; margin: 0;" alt="\alpha" /> I can accomodate different degrees of rate heterogenity</li><li>When  <img class="inlinemath" src="eqn014.png" WIDTH=42 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="\alpha &gt; 1" /> the curve is bell-shaped and models weak heterogeneity, with a big peak around 1</li><li>With  <img class="inlinemath" src="eqn015.png" WIDTH=42 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="\alpha &lt; 1" /> the curve resembles an exponential decay, some position are really variable and others really conserved</li></ul></li>
</ul>
<h1 id="tree-reconstruction-approaches">Tree reconstruction approaches</h1>
<ul>
<li>The number of possible trees increases rapidly when increasing the number of nodes: this is the tree-space
<ul>
<li>With 3 OTUs I have just 1 possible tree</li>
<li>With 4 OTUs I have 3 possible trees</li>
<li>With n OTUs I have  <img class="inlinemath" src="eqn016.png" WIDTH=151 HEIGHT=21 STYLE="vertical-align: -5px; margin: 0;" alt="(2n-5)!2^{n-3}(n-3)!" /> possible trees</li></ul></li>
<li>The best tree can be searched with an algorithmic distance-based or characther-based approach (tree search)</li>
<li>Algorithmic approach: first obtains the distances, and from them draw the tree
<ul>
<li>These methods are based on pairwise distances</li>
<li>UPGMA, WGMA, Neighbour-joining are in this category</li>
<li>It is really easy to get wrong trees with them!</li>
<li>They were initially developped for phenograms (trees based on phenotypic features)</li>
<li>Now they are applied for the construction of ultrametric trees
<ul>
<li>A tree is ultrametric when the OTUs are equidistant from the root</li>
</ul></li>
<li>In general, I start from the most similar sequences and I join them in a new OTU, and I proceed like this until I join all the OTUs</li>
</ul></li>
<li>Tree search: find the tree that maximises an optimality criterion, also called objective function
<ul>
<li>In general these are function for scoring a give tree, not a series of step for obtaining it</li>
<li>Maximum likelyhood, maximum parsimony are in theis category</li>
<li>They can be refined by bayesian inference</li>
<li>They determine which tree is more likely, given the sequences</li>
<li>They are more reliable than algorithmic methods</li>
<li>In charachter-based methods I need to know the ancestral sequence!</li>
<li>An exaustive search is almost always impossible
<ul>
<li>The branch and bound approach is a possible solution: I create an optimal tree with a subset of sequences and I add a sequence at a time</li>
<li>I can employ some heuristics</li>
</ul></li>
</ul></li>
<li>There are methods that combine the approaches: I create a starting tree with neighbor joning and then refine it with other approaches
<ul>
<li>I can also start from a tree supplied from the user</li>
</ul></li>
<li>UPGMA and WPGMA are also called clustering methods</li>
<li>WPGMA: the distance from a node k to another node u is the average of the distances of the children of k to u
<ul>
<li>Weighted pair group method with arithmetic mean</li>
<li>When I join 2 OTUs A and B, I place them at the same distance from the parent node</li>
<li>Now the distance from the (A,B) node to any other node is the average of the distances from the node to A and B</li>
<li>When joining the node (A,B) with the node (C,D), their distance is the average among the distace C to (A,B) and D to (A,B)</li>
</ul></li>
<li>UPGMA: like WPGMA but the average is weighted on the numerosity of the OTUs under a node
<ul>
<li>Unweighted pair group method with arithmetic mean</li>
<li>Unweighted refers to the fact that each distance contributes equally to the average, so the actual avergae is weighted on the numerosity!</li>
<li>In an ultrametric tree it gives the same result as WPGMA</li>
</ul></li>
<li>Both WPGMA and UPGMA are really sensitive to differences in rate of mutation among branches (differential branch lenght from a single split)
<ul>
<li>This is defined as rate heterogeneity</li>
<li>When I average 2 sequences I am assuming that their rate heterogeneity is equal!</li>
</ul></li>
<li>To overcome the limitation of clustering methods, algorithms based on additive distances were developped</li>
<li>Addittive distances satisfy the four point metric condition for any 4 taxa A, B, C, D that are joined as (A,B) and (C,D)
<ul>
<li> <img class="inlinemath" src="eqn017.png" WIDTH=257 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="d_{ab}+d_{cd} \leq max(d_{ac}+d_{bd},d_{ad}+d_{bc})" /></li><li>This is because the branch among the internal nodes is always &gt;= 0</li>
<li>This means that I can estimate distances among taxa by summing intermediate distances</li>
</ul></li>
<li>Addittive trees are always superior when the tree is not ultrametric
<ul>
<li>This is when the sequences do not follow a clock-like behaviour</li>
</ul></li>
<li>Real dataset can deviate from the four-point metric because of noise
<ul>
<li>In this case I need to artificially add a systematic error to correct</li>
</ul></li>
<li>Minimum evolution (ME) is a tree scoring function that selects the tree that minimizes overall branch lenght
<ul>
<li> <img class="inlinemath" src="eqn018.png" WIDTH=96 HEIGHT=23 STYLE="vertical-align: -5px; margin: 0;" alt="S = \sum_{i=1}^{2n-3} v_i" /></li><li>There are 2n-3 branches in an unrooted tree of n OTUs, and I am assuming that distances are addittive</li>
<li>In this method branch lenght is inferred from pairwise genetic distances</li>
<li>An exaustive ME search is practically impossible with more than 10 sequences because of the numerosity of the possible trees</li>
</ul></li>
<li>Neighbor-joining (NJ) is an heuristic used for estimating the ME tree
<ul>
<li>It is conceptually related to clustering but it does not assume clock-like behaviour</li>
<li>It minimizes the metric S of ME locally, in pairwise comparisons, but it does not guarantee to find the global minimum of the metric S</li>
<li>I always start from a distance matrix</li>
<li>I calculate for every OTU the net divergence r as the sum of the distances from the OTU to all the other OTUs
<ul>
<li>It is basically the sum of the colum of the matrix corresponding to the OTU</li>
<li> <img class="inlinemath" src="eqn019.png" WIDTH=141 HEIGHT=19 STYLE="vertical-align: -4px; margin: 0;" alt="r_a = d_{ab}+d_{ac}+d_{ad}" /></li></ul></li>
<li>I create a rate-corrected matrix by subtarcting from the pairwise distances the sum of the net divergences of the 2 OTUs considered divided by n-2
<ul>
<li> <img class="inlinemath" src="eqn020.png" WIDTH=140 HEIGHT=19 STYLE="vertical-align: -4px; margin: 0;" alt="M_{ab} = d_{ab} - r_a - r_b" /></li><li>n is the total number of OTUs</li>
<li>n-2 are the degrees of freedom</li>
<li>Note that in this matrix I have negative values</li>
</ul></li>
<li>Now I join the closest OTUs (most negative score) in the trasposed matrix</li>
<li>I calculate the distance from the node to the OTUs</li>
<li>I create a new distance matrix with the OTUs fused using the four-point condition
<ul>
<li>I know the distance of the C from A from the original matrix</li>
<li>I know the distance from A to the new node because I just calculated it</li>
<li>The distance from D to the node is thus the difference among them, since the tree is addittive</li>
</ul></li>
</ul></li>
<li>Maximum parsimony: the tree or set of trees that can be explained with the minimum number of evolutionary changes
<ul>
<li>This criterion follows from the Okham’s Razor
<ul>
<li>There is no real statistical justification</li>
<li>It is still useful as a fallback method when computational power is an issue for maximul likelihood methods</li>
</ul></li>
<li>Parsimony works better when evolution is slow, but this is NOT an assumption of the method</li>
<li>It is difficult to state the assumptions of a parsimony method, but we can say when it is good and when it suffers
<ul>
<li>Parsimony doesn’t work well with long branch attraction
<ul>
<li>Long branch attraction is when 2 long branches (distant nodes) are clustered because they both diverged a lot from the original, not because they are similar</li>
<li>The similarity arises by chance, is more diversity from all the rest</li>
<li>It is a systematic error</li>
</ul></li>
<li>It fails catastrofically in the Felsentein zone
<ul>
<li>It converges on the wrong tree with increasing certainty as more data are added</li>
<li>The Felstenstein zone is when unrelated taxa share more identity than related taxa by chance</li>
</ul></li>
</ul></li>
<li>Not all variable sites are necessarily used: only those for which the ancestral state is known or can be guessed
<ul>
<li>Singlets are excluded (mutation observed only in 1 sequence)</li>
</ul></li>
<li>The objective function of MP is the lenght L of the tree  <img class="inlinemath" src="eqn021.png" WIDTH=11 HEIGHT=10 STYLE="vertical-align: -1px; margin: 0;" alt="\tau" /> <ul>
<li> <img class="inlinemath" src="eqn022.png" WIDTH=106 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="L(\tau) = \sum_{i=1}^n l_i" /></li><li>n is the number of charachters in the MSA</li>
<li>l is the lenght of that specific charachter</li>
</ul></li>
<li>For every charachter l is the number of changes implied by the tree times the cost of each change
<ul>
<li> <img class="inlinemath" src="eqn023.png" WIDTH=113 HEIGHT=23 STYLE="vertical-align: -5px; margin: 0;" alt="l_i = \sum_{k=1}^{2n-3} c_{a_kb_k}" /></li><li>In the simplest model the cost is 0 if the position is conserved, 1 otherwise</li>
</ul></li>
<li>The costs can be represented by a cost matrix
<ul>
<li>The matrix is symmetrical, so that the lenght of the tree is constant regardless of the position of the root</li>
</ul></li>
<li>There are dynamic programmim approaches for finding the optimal tree</li>
</ul></li>
<li>Branch and bound: an algorithm for exhaustive search that prunes some of the possibilities
<ul>
<li>It can be applied to MP, but it can use any optimality criterion</li>
<li>In practice it is applicable for 15-25 taxa</li>
<li>I do an exhaustive search by progressively adding taxa to the tree</li>
<li>I keep track of the best solution until now while doing so</li>
<li>If I find a subtree with not all the taxa added that is worse than the best tree that I have, I stop evaluating it
<ul>
<li>It will never give a result which is better than the one that I have</li>
</ul></li>
<li>It is like  <img class="inlinemath" src="eqn024.png" WIDTH=31 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="\alpha/\beta" /> pruning</li></ul></li>
<li>Maximum likelyhood: optimize the likelyhood of observing the data given the model
<ul>
<li>Likelihood is a posterior probability: it is the probability of the dataset given the model</li>
<li>For a state of a particular position, its probability is evaluated as the ration among the count for the state and the total count for the position
<ul>
<li> <img class="inlinemath" src="eqn025.png" WIDTH=59 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="\theta = h/n" />, where h is the count of the state and n the total count</li><li>This is a probability, not a likelyhood, I am now building the model given the dataset</li>
</ul></li>
<li>ML is a Markov model that combines the probability of a given carachter state at all nodes
<ul>
<li>The models that I use are the GTR, HKK, ecc.</li>
</ul></li>
<li>The likelihood of the tree L is the product of the likelyhood of all sites s
<ul>
<li> <img class="inlinemath" src="eqn026.png" WIDTH=72 HEIGHT=23 STYLE="vertical-align: -8px; margin: 0;" alt="L = \prod_j s_j" /></li></ul></li>
<li>Since L is usually really small, -Log L is usually used as an optimality criterion</li>
<li>It is used much more than maximum parsimony</li>
</ul></li>
<li>Typically MP gives me a set of equally good trees while ML tends to give only 1 tree</li>
</ul>
<h1 id="nodal-support">Nodal support</h1>
<ul>
<li>Given discording predicitons, I can elaborate a consensus tree</li>
<li>A strict consensus tree has polytomies for each disagreement</li>
<li>A consensus based on the majority rule chooses the nodes that appear in most fundamental trees</li>
<li>We need a measure for node statistical significance: nodal support
<ul>
<li>There is a sampling bias in tree reconstruction: we cannot sample the entire population of a species</li>
<li>I never know if my sample is representative of the population</li>
</ul></li>
<li>We distinguish broadly resampling techniques and character-based approaches</li>
<li>Bootstrap analysis: random resampling with replacement
<ul>
<li>It is useful when I don’t know the sampling distribution and I cannot derive it</li>
<li>I approximate the real distribution by resampling</li>
<li>Bootstrapping means to take a subset of the columns of the MSA with replacement until I get an alignment of the original lenght
<ul>
<li>Since there is replacement I can have the same column twice and not have some columns</li>
</ul></li>
<li>The new shuffled and resempled alignment is called bootstrap replicate</li>
<li>I create in this way a series of bootstrap replicates for my dataset</li>
<li>I can get a tree from each replicate</li>
<li>The statistical support for a node is the fraction of tree replicates in which the node is present</li>
<li>Bootstrap results cannot detect systematic errors in tree reconstruction
<ul>
<li>It is not suitable when LBA (long branch attraction) is likely</li>
</ul></li>
<li>They also cannot detect a biased sample</li>
</ul></li>
<li>Jacknife analysis: random resampling by independent removal
<ul>
<li>It is similar to bootstrap analysis, but I randomly remove one (or more) of the sites in each resampling</li>
<li>My new subset is thus shorter than the original</li>
<li>Like in bootstrap, I can get many subsets and I create a tree for each of them</li>
<li>The jacknife support for a subtree is the fraction of times it appears in the subsets</li>
</ul></li>
<li>In both bootstrap and jacknife I should be suspicious when the support is under 70%
<ul>
<li>200 to 2000 resamplings are usually recommended</li>
</ul></li>
<li>Bremer support or deacy index: a method for testing maximum parsimony
<ul>
<li>The decay index is the difference in lenght between the shortest tree and the shortest tree that is incompatible with the node
<ul>
<li>In MP the lenght is measured as number of mutations</li>
</ul></li>
<li>I start from the best tree in MP and I count the number of steps needed to make a node collapse</li>
<li>If I need 2 additional mutations from the best tree to make a node disappear, the decay index is 2</li>
</ul></li>
</ul>
<h1 id="bayesian-analysis">Bayesian analysis</h1>
<ul>
<li>In the Bayesian framework I update my beliefs with new observations
<ul>
<li>I go from a prior belief, to a posterior belif which is the prior conditioned on the data</li>
</ul></li>
<li>It is impossible to go from  <img class="inlinemath" src="eqn027.png" WIDTH=52 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(d|M)" /> (likelyhood) to  <img class="inlinemath" src="eqn028.png" WIDTH=52 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(M|d)" /> (posterior probability) without knowing  <img class="inlinemath" src="eqn029.png" WIDTH=39 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(M)" /> <ul>
<li> <img class="inlinemath" src="eqn029.png" WIDTH=39 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(M)" /> is called prior in bayesian jargon</li><li> <img class="inlinemath" src="eqn028.png" WIDTH=52 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(M|d)" /> is a posterior<ul>
<li>It is the probability of the prior update with the available data</li>
</ul></li>
</ul></li>
<li>If I don’t know anything about the prior I can use a uniform distribution
<ul>
<li>I consider all possible values equally likely</li>
</ul></li>
<li>If I calculate a tree with Bayes, there is no need for validation
<ul>
<li>What I am using for evaluating trees is already the probability of the tree being correct!</li>
</ul></li>
<li>In this calculations I can ignore  <img class="inlinemath" src="eqn030.png" WIDTH=30 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(d)" /> since it is constant for all models<ul>
<li> <img class="inlinemath" src="eqn031.png" WIDTH=175 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(d) = \sum_M p(d|M)p(M)" /></li></ul></li>
<li>I can therefore assume that  <img class="inlinemath" src="eqn032.png" WIDTH=164 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="p(M|d) \propto p(d|M)p(M)" /></li><li>If I already know something about the taxonomy of the OTUs, I can include them in the prior</li>
<li>Markov chain Monte Carlo sampling (MCMC): estimate the posterior distribution
<ul>
<li>This method is intrinsic to Bayesian inference: I have a prior, I update it with new data, and I continue lihe this
<ul>
<li>The new data are the estimated tree topologies at every iteration</li>
<li>For each topology I have a prior, and I update it with the ML estimate, getting the posterior</li>
</ul></li>
<li>In most cases it is impossible to estimate the posterior distribution analytically</li>
<li>I build a Markov chain that converges on my posterior probability distribution</li>
<li>There are many algorthms, but the most used is the Metropolis-Hasting</li>
<li>I start from a random point in the parameter space  <img class="inlinemath" src="eqn033.png" WIDTH=10 HEIGHT=16 STYLE="vertical-align: -1px; margin: 0;" alt="\theta" /></li><li>I nudge it randomly so to get a different point</li>
<li>I calculate the ratio among the posteriors evaluated with the 2 parameter sets</li>
<li>If the new posterior is higer I take it, if it is lower I reject it</li>
<li>I continue like this until convergence</li>
<li>I can allow to sometimes accept a decrease in my probability to not be trapped in local maxima</li>
<li>The first stage of the MCMC is usually really fast-increasing and it is called burnin</li>
<li>After I while I can reach a plateu and I start to wonder around
<ul>
<li>It is important to continue the analysis at the plateau so to map the region</li>
<li>This is called mixing behaviour</li>
<li>I can tune the mixing by changing the size of jumps</li>
</ul></li>
<li>It can be difficult to understand when I am at convergence</li>
</ul></li>
<li>In certain conditions the Bayesian analysis consistently overestimates the probability of clades, when compared with ML</li>
</ul>
<h1 id="ultrametric-trees">Ultrametric trees</h1>
<ul>
<li>Ultrametric trees represent divergence time using branch lenght: they are also called time trees</li>
<li>In order to build a time tree I need a measure of the time of divergence, which is usually obtained from studying the number of substitutions in a brnach: a molecular clock</li>
<li>The simplest molecular clock assumes constant substitution rate, and this is really unlikely in nature</li>
<li>The time of divergence can be calculated from the substitution rate and the observed number of substitutions (which is the branch lenght!)  <img class="displaymath" src="eqn034.png" WIDTH=60 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="t = bl/\mu" /></li><li>Different branches tend to evolve at different rates, and we can take account of this by using a relaxed clock</li>
<li>A strict clock assumes constant  <img class="inlinemath" src="eqn004.png" WIDTH=12 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\mu" /> across all branches</li><li>The likelyhood test ratio (LTR) can be used to test the suitability of a strict clock on the dataset  <img class="displaymath" src="eqn035.png" WIDTH=679 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="LTR = 2 (\log L_{clock}-\log L_{non-clock}) \qquad L \mbox{ is the likelyhood of the dataset under the given model}" /></li><li>Closely related organisms tend to have similar substitution rates
<ul>
<li>I can probably assume a strict clock among subspecies, but probably not among different species</li>
</ul></li>
<li>Substitution rates are affected by generation time, DNA repair, selection regime, UV exposure, and other factors</li>
<li>The relative rate test compares the substitution rates of sister nodes using an outgroup as a reference</li>
<li>The Tajima test checks the difference among the number of characters shared by the outgroup and only one of the 2 ingroups and that shared with the other ingroup
<ul>
<li>I expect the same number of non-shared mutation among the 2 ingroups and the outgroup under a strict clock</li>
</ul></li>
<li>The branch lenght test compares the deviation of the distance from the root to the leaf with the average root-leaf distance in the tree</li>
<li>The local clock is a generalization of the strict clock: it assumes a different strict clock for each branch
<ul>
<li>The mutation rate remains constant in a single branch through time</li>
</ul></li>
<li>The autocorrelated relaxed clock is similar to the local clock in that assumes a possibly different clock for each branch, but it enforces more constraints
<ul>
<li>It assumes that closer branches will have a more similar clock than far branches</li>
<li>This is biologically justified by the fact that similar OTUs will share triats that affect the clock in similar ways</li>
<li>In practice the rates of the branches originating from a node are drawn from a distribution centered on the rate of the parental branch</li>
</ul></li>
<li>The general relaxed clock assumes that each branch has a different substitution rate, but these rates are drawn from the same distribution
<ul>
<li>By enforcing the rates to come from a pre-determined distribution, it is effectly less heavily parameterized than a local clock</li>
</ul></li>
<li>Non-parametric rate smoothing (NPRS) is another approach used for the calculation of substitution rates
<ul>
<li>It relaxes the assumption of a molecular clock by using a least squares smoothing of local estimates of substitution rates</li>
<li>For each node  <img class="inlinemath" src="eqn036.png" WIDTH=11 HEIGHT=16 STYLE="vertical-align: -1px; margin: 0;" alt="k" /> I calculate a value  <img class="inlinemath" src="eqn037.png" WIDTH=16 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="r_k" /> as  <img class="displaymath" src="eqn038.png" WIDTH=202 HEIGHT=21 STYLE="vertical-align: -5px; margin: 0;" alt=" r_k = (\mu_1 - \mu_2)^2+(\mu_1 - \mu_3)^2" /></li><li> <img class="inlinemath" src="eqn039.png" WIDTH=18 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\mu_1" /> is the rate of the branch that leads to node  <img class="inlinemath" src="eqn036.png" WIDTH=11 HEIGHT=16 STYLE="vertical-align: -1px; margin: 0;" alt="k" />,  <img class="inlinemath" src="eqn040.png" WIDTH=18 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\mu_2" /> and  <img class="inlinemath" src="eqn041.png" WIDTH=18 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="\mu_3" /> is the rate of the branches from node  <img class="inlinemath" src="eqn036.png" WIDTH=11 HEIGHT=16 STYLE="vertical-align: -1px; margin: 0;" alt="k" /> to its 2 children</li><li> <img class="inlinemath" src="eqn037.png" WIDTH=16 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="r_k" /> will be 0 if all the rates are equal, and bigger than 0 if they differ in any way</li><li>I then calculate a global value for the tree  <img class="inlinemath" src="eqn042.png" WIDTH=15 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="R" /> by summing  <img class="inlinemath" src="eqn043.png" WIDTH=10 HEIGHT=10 STYLE="vertical-align: -1px; margin: 0;" alt="r" /> over all the nodes  <img class="displaymath" src="eqn044.png" WIDTH=77 HEIGHT=39 STYLE="vertical-align: -20px; margin: 0;" alt=" R = \sum_k r_k" /></li><li>When I fit the model to the data, I also try to minimize  <img class="inlinemath" src="eqn042.png" WIDTH=15 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="R" /></li><li>Basically I am penalizing sharp rate transitions among branches</li>
<li>I can use the  <img class="inlinemath" src="eqn042.png" WIDTH=15 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="R" /> as a prior in a Bayesian framework</li></ul></li>
</ul>
<h1 id="molecular-clock-calibration">Molecular clock calibration</h1>
<ul>
<li>We can get a reference point from geological information (i.e. when two landmasses separated)
<ul>
<li>Geological time references are frequently really uncertain, since they happen in long timescales</li>
</ul></li>
<li>The fossil record is quite uncertain, since it is discontinuous
<ul>
<li>For many species I don’t have a fossil available, or I can have fossils only in specific timepoints with long gaps in between them</li>
<li>Fossil preservation can influence my time estimate and also the attribution of the fossil to a certain clade.</li>
<li>If the fossil is really uncomplete or degraded I cannot be sure of the clade it belongs to!</li>
<li>In general, from a fossil I can get a lower time boundary
<ul>
<li>A fossil of a clade tells me that te clade itself cannot be more recent than the fossil, but it can be older!</li>
</ul></li>
</ul></li>
<li>In Bayesian analysis I can use the time estimate as a prior
<ul>
<li>In this way I can also model the time uncertainty (an hard minimum timeborder and a more flexible maximum time border) by tweaking the prior probability distribution</li>
<li>Usually an exponential distribution is used as a model for fossil-record timepoints, since it reflects the soft-hard boundary pair</li>
<li>The lognormal distribution also can model this uncertainty
<ul>
<li>It has a high region near the cutoff that decreases sharply towards the minimum and slowly towards the maximum</li>
<li>It is the probability distribution of a random variable whose logarithm is normally distributed.</li>
</ul></li>
<li>The normal distribution is more used for timepoints that do not derive from fossils
<ul>
<li>It is a symmetric distribution, so it cannot implement an asymmetric soft-hard boundary. It is used for geological data</li>
</ul></li>
<li>The uniform distribution is the one that implies less assumptions, but it is also the less informative
<ul>
<li>It is used for calibrating the root, since it is the point of the tree of which we usually know less</li>
</ul></li>
</ul></li>
<li>Calibrating a clock can require a lot of effort for collecting data to be used as a prior!</li>
<li>I can increase the reliability of my estimate by including many fixed time references in my tree</li>
<li>Sensitivity analisys: correlation of the predicitons from different methods
<ul>
<li>It can show when my Bayesian prediction are strongly influenced by the priors</li>
</ul></li>
<li>Bayesian analisys tends to be sometimes heavily influenced by priors
<ul>
<li>Nodes that are calibrated by timepoints show little difference in their age estimate after the data (sequences) have been considered</li>
<li>Nodes that do not have a prior estimate are instead heavily guided by the data</li>
<li>When doing Bayesian inference I need to be carefull to not make the priors override the data</li>
</ul></li>
</ul>
<h1 id="biases-in-phylogenetic-reconstructions">Biases in phylogenetic reconstructions</h1>
<ul>
<li>With maximum likelihood estimates I get the most likely tree given the data, but it is not necessarily the true tree</li>
<li>My data could be biased, or not representative of the population
<ul>
<li>Methods for nodal support can address this issue</li>
</ul></li>
<li>Systematic errors can derive from biases in the nucleotide composition (e.g. GC content), from saturation of the signal and from exceptional events in the evolutionary history of the OTUs</li>
<li>Sequences with a similar GC content tend to appear more related than how really are, and vice-versa for really different GC contents
<ul>
<li>GC content tend to vary a lot in the same genome and among genomes</li>
<li>Regions with similar GC content inside a genome are called isochores.</li>
<li>Different clades can have really different typical GC content
<ul>
<li>In bacteria it is reallly variables, in mammals really constant</li>
</ul></li>
<li>We don’t know why GC content varies so much
<ul>
<li>Selective mutations, differential codon usage</li>
<li>There can be a mutational bias where some mutations (e.g. AT -&gt; GC) are more frequent than their opposite (e.g. GC -&gt; AT)</li>
<li>Genome stability can also be a factor (heat adaptation)</li>
</ul></li>
</ul></li>
<li>GC content is not stable and varies over time
<ul>
<li>Our models assume that nucleotide composition is at equilibrium and when GC content changes over time this is not true</li>
</ul></li>
<li>Signal saturation happens when the observed distance reaches a plateau due to the many substitutions at the same site.
<ul>
<li>Homologies observed in saturated sequences can be due to chance instead of true homology (homoplasy)</li>
<li>This phenomenon gives rise to long branch attraction</li>
</ul></li>
<li>Branches which are really long compared to the rest of the tree tend to cluster because of chance similarities
<ul>
<li>Maximum parsimony is really sensitive to long branch attraction since it cannot model multiple substitutions</li>
</ul></li>
<li>The area of the tree space that suffers from long branch attraction is called Felsestein zone
<ul>
<li>In the Felsenstein zone likelihood methods outperforms parsimony</li>
</ul></li>
<li>In some cases however, long branches are really related to each other: this is the inverse Felsenstain zone (Farris zone)
<ul>
<li>In the Farris zone parsimony outperforms likelihood.</li>
</ul></li>
<li>The sponge war: sponges were considered the sister clade of all metazoans, but then a paper supported that Ctenophora (jellyfish) is the real sister clade
<ul>
<li>A debate started in the community and then this was dismissed</li>
<li>This mistake was probably due to long branch attraction between the outgroup and Ctenophora</li>
<li>The choice of the outgroup can introduce a bias!</li>
</ul></li>
<li>Pancrustacea is a monophiletic group that includes insects and crustaceans
<ul>
<li>The true topology of the group is debated, mainly because of many really long branches and significant compositional bias</li>
</ul></li>
<li>In time mutations tend to become fixed or extinct</li>
<li>In incomplete lineage sorting there can be fixation of a mutation in the same allele in different branches generating a case of homoplasy
<ul>
<li>This happens when there is a true split before a mutation becomes fixed</li>
<li>In this case I tend to have unstable nodes, that are not consistent among different analyses</li>
<li>This is frequent when there are multiple speciation events that are close in time (rapid radiation)</li>
</ul></li>
<li>Long branch attraction: wrong clustering of long branches
<ul>
<li>Long branches tend to carry a saturated signal</li>
<li>Random similarities can make algorithms cluster the branches together, even if they are not related</li>
<li>ML is typically better than MP when LBA is present</li>
</ul></li>
<li>Felsenstein zone: MP is likely to choose the wrong solution because of LBA
<ul>
<li>This happens when the long branches are not closely related!</li>
</ul></li>
<li>Inverse Felsenstein zone (Farris zone): MP is likely to choose the right solution in presence of long branches
<ul>
<li>This happens when the long branches are actually also closely related</li>
</ul></li>
</ul>
<h1 id="phylogenomics">Phylogenomics</h1>
<ul>
<li>Phylogenomics: I align all the possible orthologues (typically more than 50) and get a supermatrix
<ul>
<li>It is essentially a total evidence approach!</li>
<li>There are many conflicting genes in a genome</li>
<li>Sometimes the outliers drive the analysis, be careful!</li>
<li>In phylogenomics you are wrong but with high statistical support!</li>
<li>Data can be taken from genomes, but usually RNA-seq is preferred</li>
</ul></li>
<li>The best way to find potential orthologues in a reciprocal BLAST
<ul>
<li>In reciprocal BLAST I get a significant BLAST result and I BLAST it again against the query
<ul>
<li>If the result is still significant I consider the pair orthologous</li>
</ul></li>
</ul></li>
<li>Most of the work in phylogenomics is in building the matrix
<ul>
<li>The analysis is then analogous to multilocus phylogenetics</li>
<li>In phylogenomics papers they usually try with different matrices</li>
</ul></li>
<li>Phylogenomics cannot resolve errors due to base compositional bias
<ul>
<li>This can be better corrected by changing the model</li>
<li>Phylogenomics is really sensitive to model violations</li>
<li>The CAT model is usually used in phylogenomics</li>
</ul></li>
</ul>
<h1 id="supermatrix-approach">Supermatrix approach</h1>
<ul>
<li>Polytomies are non-binary splits in a tree
<ul>
<li>Hard polytomies are due to rapid radiating evolution and they are hard to solve</li>
<li>Soft polytomies are due to the use of not-enoguh informative sites for the inference</li>
<li>We can resolve polytomies by using more genes in my supermatrix</li>
<li>A bifurcating tree is one lacking polytomies</li>
</ul></li>
<li>What I am analysing in phylogenetics in not really the gene, but mostly the CDS for coding genes
<ul>
<li>Of course I can also include non-coding sequences sometimes</li>
</ul></li>
<li>The supermatrix approach: concatenate MSAs
<ul>
<li>I align several genes indipendently</li>
<li>I concatenate the alignments to get a supermatrix</li>
<li>I compare the tree obtained from the supermatrix with the single gene trees</li>
<li>I can also concatenate molecular data and classical data, codified with specific carachter states</li>
</ul></li>
<li>It is important to align the single genes independently since I don’t want to align positions of one gene with position of another!</li>
<li>When I do the phylogenetic inference, I want to use different models for the different genes
<ul>
<li>It can give better results!</li>
<li>To do so, I need to find partitions in the supermatrix</li>
<li>Partitions are most commonly the original genes that composed it, which are analysed in dependently and then the results are combined</li>
<li>In the case of coding genes I can include 3 different partitions, one for each coding frame</li>
</ul></li>
<li>Merging the trees of single genes can be done usign congruence or total evindence
<ul>
<li>Different genes can give conflicting signals!</li>
<li>Congruence: I select only the genes with non-conflicting topology</li>
<li>Total evidence: I use the supermatrix and accept the cumulative result</li>
<li>Now total evidence is favored</li>
</ul></li>
<li>Case study: Xenoturbella
<ul>
<li>It is not clear from morphology where it belongs in the animal tree</li>
<li>Early studies were based on the nuclear 18S and mythocondrial COX1
<ul>
<li>These analyses put it close to molluscs</li>
</ul></li>
<li>A 2003 study that included rare mitochondrial rearrangements places it in Deuterotostomia instead of Proteostomia (molluscs are here)
<ul>
<li>In the previous study they actually sequenced molluscs!</li>
<li>Xenoturbella eats molluscs</li>
</ul></li>
<li>A 2009 study places it again in Protostomia, but not close to molluscs</li>
<li>It seemed related to Acelomorpha</li>
<li>The same tree was built with 2 different matrices
<ul>
<li>A 330 genes full orthologous matrix</li>
<li>A 800 genes matrix with missing data</li>
</ul></li>
<li>Another study puts it in deuterostomia by taking into account compositional eterogeneity (CAT model)</li>
<li>Still deuterostomia using a set including miRNAs</li>
<li>Explanation: long branch attraction from protostomia outgroups when many of them are included</li>
<li>2016 study with no LBA puts it again in protostomia
<ul>
<li>It was caused by a cluster of non congruent genes</li>
<li>Removing these genes it was placed again in deuterostomia</li>
<li>These were all ribosomial protein genes</li>
</ul></li>
</ul></li>
<li>Molluscs are really interesting for phylogenetics
<ul>
<li>They have all really similar coalescent times near the Cambrian explosion</li>
<li>Mithocondrial DNA has uniparental inheritance but
<ul>
<li>In higher animals is always maternal</li>
<li>In molluscs in some cases is maternal, in others parental</li>
</ul></li>
<li>There is huge disagreement among mithocondrial and nuclear phylogeny!
<ul>
<li>Also nuclear genes that code for mithocondrial proteins are in agreement with mtDNA!</li>
<li>Different evolutionary history for nDNA and mtDNA!</li>
</ul></li>
</ul></li>
<li>Most uncertainty in phylogenetics inference can derive from a set of non-congruent genes!</li>
<li>The problem of missing data: I don’t have orthologs for all the species I want!
<ul>
<li>A huge bias: we have a lot of genes for some species and very few for others</li>
<li>If I want to include many genes I will have many missing data</li>
<li>Genes can be lacking because they are lost in evolution</li>
<li>There can be a sequencing problem (i.e. gene broken up in different unassembled scaffolds)</li>
<li>Some studies show that we tend to obtain the same topology if we include missing data
<ul>
<li>Usually the result is even better if we include the missing data</li>
</ul></li>
<li>If there are partial genes is it is better to exclude them
<ul>
<li>I can have different partials in different species, and this can induce false similarities</li>
</ul></li>
</ul></li>
<li>Partitioning means to find the best fitting model for each portion of the supermatrix
<ul>
<li>Different genes evolve under different constraints!</li>
<li>Not necessarily my partition overlap with the genes
<ul>
<li>I can have a partition including all the 3rd codon posititons of all genes</li>
</ul></li>
<li>They are found by the software with a best fit approach</li>
<li>I can also have different partitions that use the same model but with different parameters</li>
</ul></li>
</ul>
<h1 id="supertree-approach">Supertree approach</h1>
<ul>
<li>A supertree is a tree obtained by joining toghether different trees from different datasets
<ul>
<li>Informal construction:just join manually different trees</li>
<li>Formal construction: follows a mathematical approach</li>
</ul></li>
<li>It is used to bring together different studies, or when I do not have the possibility to do a supermatrix</li>
<li>Usually trees are joined formally when they have the same OTUs
<ul>
<li>From MP I can get many different shortest trees, and I need to reconcile this by building a consensus tree</li>
</ul></li>
<li>Consensus method: just report nodes that are in all trees
<ul>
<li>If the trees are not compatible I cannot do this</li>
<li>I can have many polytomies</li>
<li>It is very fast</li>
</ul></li>
<li>MPR approach: maximum representation with parsimony
<ul>
<li>I build a matrix where each column represents a node and each row an OTU</li>
<li>I put 1 if an OTU is included in a node, 0 otherwise</li>
<li>In the matrix I put nodes and OTUs from different trees
<ul>
<li>I label differently nodes from different trees</li>
</ul></li>
<li>If an OTU is absent from I tree I don’t put 0, but ‘?’</li>
<li>I create the supertree with MP from the matrix
<ul>
<li>I consider the 1, 0 and ‘?’ as charachters and just minimize their changes</li>
</ul></li>
<li>I can see hidden support emerging
<ul>
<li>A node absent from all the source trees can appear</li>
</ul></li>
</ul></li>
<li>A supertree is built by ignoring the underlying evidence for the single trees!</li>
<li>Disk covering approach: a faster way to elaborate big supermatrices
<ul>
<li>I create a rough tree with NJ</li>
<li>I split the tree in pieces and I use MPR to reconstruct the supertree</li>
</ul></li>
<li>Biclique approach: for incomplete datasets
<ul>
<li>I select bicliques in the dataset containing groups of orthologs</li>
<li>I get a tree for each orthologous group</li>
<li>I join the trees with MPR</li>
</ul></li>
<li>Integrative supertree/supermatrix: sometimes pipelines are complicated
<ul>
<li>I create a tree with the supermatrix</li>
<li>I create the single gene trees and I create the suprtree with them</li>
<li>I can compare them and build the consensus tree/majority rule tree</li>
<li>I can evaluate the likelyhood of the supertree with the supermatrix data
<ul>
<li>It could be better than thedirect supermatrix tree!</li>
</ul></li>
</ul></li>
<li>Something huge: the super time tree (time tree of life, TTOF)
<ul>
<li>It includes almost all the known organinsm!</li>
<li>It is a normal supertree built with time trees</li>
<li><code>timetree.org</code> is an amazing website for getting phylogeny of everithing
<ul>
<li>There is also a nice book in the website, if you have time give a look</li>
</ul></li>
</ul></li>
</ul>
<h1 id="dna-sequence-databases">DNA sequence databases</h1>
<ul>
<li>Databases are useful for making sequences freely available and for independent validation</li>
<li>If I take a sequence from a database, I have a reference for it!</li>
<li>I can find information about the taxonomy related to a sequence
<ul>
<li>NCBI is not autoritative for taxonomy, but still gives an useful indication</li>
</ul></li>
<li>I can find metadata about the sequence
<ul>
<li>In some cases I can also find in which museum the original speciment is conserved!</li>
</ul></li>
<li>The BOLD database contains a DNA barcode for many species</li>
<li>RepBase is a database of repetitive sequences</li>
<li>RNAcentral was a database about RNA sequences that now is discontinued
<ul>
<li>There are many alternatives for studying non-conding RNA sequences</li>
</ul></li>
<li>When you sequence something always BLAST it to see if you sequenced the right organism!</li>
</ul>
