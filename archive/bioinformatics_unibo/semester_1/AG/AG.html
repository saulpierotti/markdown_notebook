<h1 id="introduction">Introduction</h1>
<ul>
<li>Genomics is the study of genome structure and function</li>
<li>The genome is the entire genetic content of an organism</li>
<li>Applied genomics is the use of technologies, tools and experimental designs to analyse genome and extract information form them</li>
<li>Genetics studies differences: we cannot track things that are not different among individuals</li>
<li>A reference genome of a species is the basis used for analyzing the genome of an individual
<ul>
<li>In some cases if I do not have a reference genome I can use that of a similar species</li>
</ul></li>
<li>We have about 2 nuclear genomes per cell, but even thousands of mithocondrial genomes</li>
<li>Mithocondrial genomes can be not all equal: heteroplasmy</li>
<li>The human nuclear genome is around 3 Gb, the mithocondrial genome 16.7 Kb</li>
<li>Population genetics is important for this course</li>
<li>Small population are susceptible to high levels of inbreeding</li>
<li>Differences between population arise when there are reproductive barriers</li>
<li>Effective population size is the number of individual that originated a population
<ul>
<li>It is a measure of inbreeding</li>
</ul></li>
<li>Sex determination can be mediate by sex chromosomes, temperature, ploidy</li>
<li>Phenotype is influenced by the environment</li>
<li>A phenotype is an observable charachteristic</li>
<li>Comparative genomics is the study of genomic differences between species
<ul>
<li>It is really helpful for genome annotation</li>
</ul></li>
<li>The first draft of the human genome was completed in 2001, and the HGP was started in 1990</li>
<li>3% of human DNA is coding</li>
<li>Repetitive sequences are problematic for assembling genomes</li>
<li>Nuclear DNA is 99.99% identical among individuals, while mitochondrial genome is more similar</li>
<li>The simplest definition of gene is “coding region”</li>
<li>We can predict the phenotype of an animal just looking at the genotype (!)</li>
<li>To do applied genomics I need a reference genome</li>
<li>If I do not have a reference genome for my species of interest, I need to construct it or I can use one of a closely-related species</li>
<li>Genomics produces around 10 Zb of data per year
<ul>
<li>We cannot store everithing: we must select what is worth storing and what is not</li>
<li>It is interesting to look at portions that differ from the reference genome</li>
</ul></li>
<li>The cost of sequencing is dropping in a way similar to Moore’s law
<ul>
<li>Around 2008 the drop was much faster than Moore’s law, thanks to NGS</li>
</ul></li>
<li>The shotgun approach does not have a particular target, it sequences everything</li>
<li>Genomic data are typically stored in the cloud</li>
<li>Hardy-Weinberg equilibrium
<ul>
<li> <img class="inlinemath" src="eqn000.png" WIDTH=409 HEIGHT=53 STYLE="vertical-align: -22px; margin: 0;" alt="\begin{cases}p^2+q^2+2pq=f(AA)+f(Aa)+f(aa)=(p+q)^2=1 \\ p+q=1\end{cases}" /></li><li>The allele frequencies refer to the current generation, while the genotype frequencies refer to the next generation</li>
<li>It holds in absence of genetic drift, non-random mating, selection, migration, mutation</li>
</ul></li>
<li>Mendel’s first law: alleles segregate with other alleles</li>
<li>Mendel’s second law: independent assortment</li>
<li>Mendel’s third law: some alleles are dominant on others</li>
<li>We reviewed PCR, agarose gel electrophoresys and Sanger sequencing basics</li>
<li>Reference genomes can be found in the Ensemble database</li>
<li>Penetrance is the proportion of individual with a given genotype that manifest the associated phenotype</li>
</ul>
<h1 id="genome-structure-and-variability-in-vertebrates">Genome structure and variability in vertebrates</h1>
<ul>
<li>LINEs are autonomous repetitive sequences of 6-8 kb
<ul>
<li>The LINE1 family is the most abundant</li>
<li>There are around 50k LINEs in a genome</li>
</ul></li>
<li>SINEs are depend on LINEs for transposition and are 100-300 bp long
<ul>
<li>They are derived from the 7SL RNA</li>
<li>The 7SL RNA is involved in the signal recognition particle that guides protein translation to the ER</li>
</ul></li>
<li>Alu is a SINE and it is the most abundant repeat in primates (1M copies)</li>
<li>LINEs and SINEs are retrotransposons, transposons that move via an RNA intermediate</li>
<li>MIRs(mammalian interspersed repeats) are a type of SINE found in mammals</li>
<li>LTRs are retroviral elements and they are 1.5-3 kb long</li>
<li>DNA transposons are 2-3 kb long and code for a trasposase</li>
<li>They can be spotted with repeat masker</li>
<li>This tool can mark SINE, LINE, Alu and will mask it in my sequence</li>
<li>Masking means to substitute a sequence with a stretch of NNNN of the same length</li>
<li>Pseudogenes can be processed or non processed (with introns) and they are not recognised by repeatmasker</li>
<li>Cot curves are obtained by melting the genome and observing the re-annealing process
<ul>
<li>Before melting the genome is sheared in 1kb chunks</li>
<li>The rate limiting step of reassociation is the collision of complementary strands, a second order kinetic</li>
</ul></li>
<li>The copy number of a sequence influences the time needed for re-annealing</li>
<li>In simple genomes the cot curves are sigmoids, while in eucariots they are complex</li>
<li>Eukariotic cot curves can usually be resolved in 3 sections
<ul>
<li>An highly repetitive portion of DNA re-anneals quickly</li>
<li>A moderately repetitive region</li>
<li>Unique sequences</li>
</ul></li>
<li>To put in perspective in a human genome
<ul>
<li>Coding regions represent 1.5% of the genome</li>
<li>Conserved regions represent 3%</li>
<li>Non conserved unique regions 44%</li>
<li>Transposons are 45%</li>
<li>Constitutive heterochromatine 6.6%</li>
<li>Microsatellites 2%</li>
</ul></li>
<li>Constitutive heterochromatine is highly repetitive with short tandem repeats
<ul>
<li>It is typically centromeric or on the short arm of acrocentric chromosomes, where it forms constrictions</li>
</ul></li>
<li>Satellite DNA is that portion of the genome that when it is centrifuged it forms thin bands that are lighter than the bulk genome
<ul>
<li>Sequence density depends only on GC content</li>
</ul></li>
<li>Minisatellites are 10-30 bp long and are usuallyu near telomeres
<ul>
<li>Some of them are hypervariable (VNTRs), so they are useful for the identification of individuals</li>
</ul></li>
<li>Microsatellites (SSRs) are 2-5 bp and they are found everywhere in the genome</li>
<li>Genes are probably around 20k, most of them protein coding</li>
<li>Histone genes don’t have introns</li>
<li>More than 99% of genes is represented by introns</li>
<li>Exons are around 200 bp on average</li>
<li>Intron size is really variable, from 100 bp to several Mb</li>
<li>There are portions of mithocondrial DNA integrated in the nuclear genome
<ul>
<li>These are called NUMTS and they are mostly pseudogenes, but maybe some of them are functional</li>
<li>They are still being integrated, so they tend to be quite variable</li>
<li>The ones integrated most recently tend to be really similar to the mithocondrial sequences</li>
</ul></li>
<li>Gene families can be in tandem or interspersed</li>
<li>Instersped genes could have been moved by transposons</li>
</ul>
<h1 id="sanger-sequencing">Sanger sequencing</h1>
<ul>
<li>Sanger sequencing was developped by F. Sanger in 1977</li>
<li>It uses DNA polymerase to extend a primer using genomic DNA as a template</li>
<li>ddNTPs are incorporated in the reaction mixture in a controlled ratio
<ul>
<li>ddNTPs lack a 3’-OH and thus cannot be used for extending the DNA chain</li>
<li>The ration ddNTP/dNTP is typically around 1/100, but it depends on the lenght of the desired sequence</li>
<li>When a ddNTP is incorporated the extension reaction is interrupted</li>
</ul></li>
<li>In the original Sanger publication and in the first approaches radioactive labels were used
<ul>
<li>Either the primers were labeled, or a single dNTP (not ddNTP!) in the mixture</li>
<li>4 different reaction were performed and separately processed, each with a single ddNTP type</li>
</ul></li>
<li>In the current approach, dye-terminator sequencing, the 4 different ddNTPs are labeled with different fluorophores
<ul>
<li>The strand itself and the primers are not labeled</li>
<li>A single reaction is done with all the 4 labeled ddNTPs and run together on the capillary gel</li>
</ul></li>
<li>The ssDNA fragments are run in a capillary electrophoretic apparatus
<ul>
<li>ssDNA hairpins are a serious probelm for lenght resolution</li>
<li>A denaturing polyacrilamide-urea gel is used</li>
</ul></li>
<li>In dye-terminator sequencing an electropherogram is produced, showing fluorescent intensity peaks for each of the 4 channels</li>
<li>Sanger sequencing primers are designed according to the region that I want to sequence
<ul>
<li>In general I use Sanger when I have a reference!</li>
</ul></li>
</ul>
<h1 id="next-generation-sequencing">Next generation sequencing</h1>
<ul>
<li>NGS platforms: Illumina, Ion torrent (Thermo fisher), PacBio, Nanopore, 454
<ul>
<li>PacBio was going to be acquired by Illumina, but the antitrust opposed and the merger was canceled</li>
<li>We have short reads, therefore assembly is difficult</li>
<li>454 (La Roche, pirosequencing) is practically dead today</li>
</ul></li>
<li>The depth of coverage is the number of unique reads that contain a specifc nucleotide in the assembly</li>
<li>Sequencing a mammalian genome at 50x costs around 2000€+VAT in China or South Korea
<ul>
<li>BGI (Bejing genome institute) is the largest sequencing provider and it is chinese</li>
<li>NOVOGENE is from South Korea</li>
<li>If I chose to use these services, I need to consider shipping restrictions, costs, and product degradation</li>
</ul></li>
<li>In sequencing, if we are not sure about a variant we exclude it</li>
<li>When I do genotyping by sequencing, the regions of interest have a very high depth of coverage so I can trust the results</li>
<li>We have tools for allignment of reads to a reference like bowtie
<ul>
<li>They produce a BAM file</li>
</ul></li>
<li>There are tools for calling mutations, Indels, ecc.</li>
<li>Fastq is similar to fasta but it has additional information on it
<ul>
<li>It uses ASCII symbols to code a quality score (PHRED score, from the homonimous software) in a separate line from the one where the bases are stored
<ul>
<li>PHRED uses hard-code lookup tables of peak charachteristics to estimate quality</li>
</ul></li>
<li>The highest quality is 93 for fastq</li>
<li>The quality score is the ASCII code of the charachter (!)
<ul>
<li>ASCII 33 to 126 are used, encoding scores from 0 to 93</li>
</ul></li>
<li>The quality score rarely exceeds 60 in raw data, but can be higher in assemblies</li>
<li>The threshold quality score now accepted for base calling is 30</li>
</ul></li>
<li>Illumina reads file looks like a fastq, but quality scores have a different scale
<ul>
<li>If my file has scores higher than 90, it is an Illumina file</li>
</ul></li>
<li>Allignments are saved in .sam format, a tab-delimited text file that can be converted in a binary .bam file
<ul>
<li>The sam file contains the sequence of reads, their genomic alignment coordinate, contig, mate read name</li>
<li>samtools is used for working with sam files</li>
</ul></li>
<li>Sequencers are actually high-performance PCs with Intel Xeon CPUs and 48 Gb of RAM!</li>
<li>The NGS platforms that are not portable are so because the optics cannot be miniaturized</li>
<li>Paired-end reads are obtained by reading a short fragment from both directions
<ul>
<li>If the fragment is short I just sequence it 2 times in opposing directions</li>
<li>If the fragment is longer I get information about 2 sequence at a known distance from each other</li>
</ul></li>
<li>Mate pairs are obtained from long fragments (2-5 kb)
<ul>
<li>I biotinylate the ends of the fragment</li>
<li>I make the fragment circular by pairing the biotinylated ends</li>
<li>I Break the circular fragment in 200-600 bp pieces</li>
<li>I select the fragment containing the biotyn (and so the opposing ends of the original 5 kb fragment)</li>
<li>I sequence it in pared-end reads: I know 2 sequences that are 5 kb apart</li>
</ul></li>
</ul>
<h2 id="ion-torrent">Ion torrent</h2>
<ul>
<li>There are many sequencing chips, with different throughputs</li>
<li>The sequencing device is a semiconductor chip with millions of nano-wells
<ul>
<li>Each well is represented as a pixel</li>
</ul></li>
<li>DNA fragments are clonally amplified on acrylamide beads that are poured on the chip and go in the wells, one for each well</li>
<li>The chip is sequentially flodded with the 4 nucleotides, allowing a stepwise progression of DNA synthesis</li>
<li>The addition of a nucleotide releases a proton, changing the pH of the well</li>
<li>The drop in pH is recorded as a base call for the well</li>
<li>I have clonal amplification on positively charged spheres</li>
<li>During the addition of a nucleotide, a proton is released</li>
<li>If I add nucleotides one at a time, I can sense the pH change due to the many protons released by the clones</li>
<li>If I have multiple nucleotides of the same type in a row, I get a stronger signal</li>
<li>Regions with a stretch of the same nucleotide are called omopolymeric
<ul>
<li>It is difficult to exactly count the number of nucleotides in these regions</li>
</ul></li>
<li>The raw data produced is called ionogram</li>
<li>We use universal adapters with a specific portion to amplify the DNA fragments</li>
<li>The machine is called ion or proton torrent</li>
<li>In the preparation step we obtain thousands of template molecules</li>
<li>The first step of the workflow is library preparation</li>
<li>Library preparation depends on the kind of samples</li>
<li>I can sequence amplicons, genomes, RNA libraries</li>
<li>I can only sequence small fragments: I need a fragmentation step</li>
<li>Fragmentation can be done by sonication or with aspecific DNases</li>
<li>Playing with the time of fragmentation, I can modulate the length of the fragments</li>
<li>Frequently I need to try in different ways (!)</li>
<li>It is a random process!</li>
<li>I have to amplify all my fragments by PCR</li>
<li>It will take forever with standard PCR, so I do emulsion PCR where every drop harbours a reaction</li>
<li>I then do an electrophoresis to get only the fragments of a certain size</li>
<li>NGS can typically sequence from 25 up to 400 nucleotides, but the highest throughput is around 100 BP per read</li>
<li>The ideal case is that in a droplet I have a bead and a single DNA fragment</li>
<li>The DNA attached to the acrylamide beads after emulsion PCR is retrieved with the ion sphere particle enhancement technique
<ul>
<li>I use magnetic beads with streptavidin to capture the amplified acrylamide beads</li>
<li>The beads bind biotin-labeled nucleotides on the beads, so this will select only sucessfully amplified beads</li>
<li>After magnetic pull I denature the streptavidin and release the acrylamide template beads</li>
</ul></li>
<li>To increase my output, I can regolate my flow (nucleotides added) considering gc content of my target
<ul>
<li>One flow is the addition of 1 nucleotide to the chip</li>
</ul></li>
<li>The real throughput of my sequencing system is lower than the theoretical one
<ul>
<li>If 2 different fragments are amplified together I get mixed reads, and they give me false sequences as output</li>
<li>I need to ignore the mixed reads, but they will waste some of my sequencing wells</li>
<li>The same for 2 beads with the same fragment: duplicate reads</li>
</ul></li>
<li>The ionogram is expected to show on average a peak every 4 flows
<ul>
<li>If I see too many peaks close to each other, I probably have mixed reads</li>
</ul></li>
<li>I have a reference sequence known, and if this sequence reaches a threshold signal I keep my read, otherwise I discard it</li>
<li>In missed reads I have too many empty spaces in each read, more than statistically reasonable</li>
<li>Ion torrent reads are longer than Illumina, around 400 bp, and it runs in a shorter time (2 to 7 hours)</li>
<li>A single run produces 50 Mb to 15 Gb raw</li>
<li>Ion torrent is now specialising in clinical applications with the PGM machine</li>
<li>Usually it does not support paired-end sequencing, but the PGM sequencer does</li>
</ul>
<h2 id="roche-454">Roche 454</h2>
<ul>
<li>It works in similar way to Ion Torrent, but it senses the release of pyrophosphate during elongation
<ul>
<li>NUcleotides are added in flows like for ion torrent</li>
<li>PPi and adenylil-sulfate are converted to ATP and sulfate by sulfurylase (Sulfate adenylyltransferase)</li>
<li>ATP is used by luciferase releasing a photon</li>
<li>APyrase continously removes excess NTPs that are not incorporated</li>
</ul></li>
<li>It was the first NGS to be developped, but also the first one to become obsolete</li>
<li>Like Ion Torrent, it uses beads on a chip and the target is amplified by emulsion PCR</li>
<li> <img class="inlinemath" src="eqn001.png" WIDTH=30 HEIGHT=17 STYLE="vertical-align: -4px; margin: 0;" alt="PP_i" /> is used by sulphurylase to synthetize ATP, ATP is used by luciferase to produce light</li><li>Light emission is sensed by a CCD camera producing a pyrogram</li>
<li>This technique was abandoned because it is too expensive
<ul>
<li>The cost is mainly due to the many enzymes used (sulphurylase, luciferase, apyrase)</li>
<li>The CCD camera is expensive</li>
</ul></li>
<li>It has revolutionized bacterial taxonomy because it allowed to sequence the rRNA 16s
<ul>
<li>This is because it can produce longer reads than other NGS techniques</li>
</ul></li>
<li>It can produce 500 Mb per run with a read lenght of 400-600 bp</li>
</ul>
<h1 id="illumina">Illumina</h1>
<ul>
<li>Library preparation
<ul>
<li>DNA is fragmented by sonication</li>
<li>Overhangs are blunted or repaired
<ul>
<li>I use T4 polymerase and Klenow fragment for repair and blunting</li>
<li>Polymerase activity fills the 5’ overhangs and exonuclease activity removes the 3’ overhangs</li>
</ul></li>
<li>All the 5’ ends are poshporylated, since their status is unknown after sonication
<ul>
<li>I use T4 PNK</li>
</ul></li>
<li>A single A is added at the 3’ of the fragments to avoid ligation of different fragments in the blunt ligation step
<ul>
<li>Adapter on the contrary have a single T 3’ overhang to facilitate ligation with the fragments</li>
</ul></li>
<li>Adapters are ligated to fragments with ligase</li>
<li>PCR is used for selectively amplifying fragments that have been correctly ligated to adapters
<ul>
<li>The primers anneal to the end of the adapter and have a tail that adds sequences used for the library amplification in the flowcell</li>
</ul></li>
</ul></li>
<li>In a flowcell, I have many oligos that can anneal with the inserted sequences at the end of the adapters</li>
<li>Bridge amplification amplifyes the fragments in the flowcell</li>
<li>After bridge-amplification, I get clonal clusters of fragments</li>
<li>In the elongation step I add all the nucleotides together, marked with fluorophores and reversibly inhibited at their 3’
<ul>
<li>These modified nucleotides are called reversible dye terminator chemistry</li>
<li>The primers used anneal to the adapter that is not part of the flowcell</li>
</ul></li>
<li>The elongation is stepwise because there is a block in 3’ that inhibits elongation
<ul>
<li>I can easily deal with homoplimeric regions (!)</li>
<li>Because of this the error rate is much lower</li>
</ul></li>
<li>After nucleotide incorporation I excite the flowcell with laser and capture the resulting fluorescence with a CCD camera</li>
<li>An enzimatic step that cleaves the 3’ block and the fluorophore</li>
<li>I can sequence both ends of my fragments, and this is really useful for the assembly step
<ul>
<li>I can play with fragment size to obtain my contigs</li>
</ul></li>
<li>When I sequence a genome, I need to consider sequencing depth and coverage
<ul>
<li>Sequencing depth is the average number of times that a nucleotide in my reference genome is represented in a read</li>
</ul></li>
<li>In order to reduce cost, I can run more samples in the same lane by using a barcode attached to my fragments</li>
<li>MySeq can be used for metagenomics (16S sequencing, 24 samples per lane) and for microbial WGS
<ul>
<li>It can procduce 3-7 million reads per lane</li>
</ul></li>
<li>HiSeq can be used for WGS (3-4 lanes per genome) and exome capture (4 samples per lane)
<ul>
<li>It can procduce 100-160 million reads per lane</li>
</ul></li>
</ul>
<h2 id="ab-solid">AB SOLiD</h2>
<ul>
<li>It is dead by now, but could be potentially great because it gives the highest throughput</li>
<li>Its reads are really short (30 bp) so it is computationally heavy to asseble the reads and it is impossible to use with repetitive regions</li>
<li>It is based on sequencing by oligo ligation detection</li>
<li>DNA is fragmented and ligated to P1 and P2 adapters
<ul>
<li>I can prepare simple or mate-paired libraries</li>
<li>Mate-paired libraries use also an internal adapter</li>
</ul></li>
<li>A clonal population of beads is created from the fragments by emulsion PCR</li>
<li>Beads are covalently attached to a glass slide</li>
<li>The slide is incubated with an universal sequencing primer, di-base probes and DNA ligase</li>
<li>The primer has its 5’P oriented towards the fragment (away from the bead)</li>
<li>There are 16 (all the possible  <img class="inlinemath" src="eqn002.png" WIDTH=16 HEIGHT=17 STYLE="vertical-align: -1px; margin: 0;" alt="4^2" /> 2-mers) different dibase probes, marked with 4 different fluorophores<ul>
<li>Each dye could correspond to 4 of the 16 di-base probes</li>
<li>The probes have the di-base specific sequence at the 3’ and 6 additional aspecific positions at their 5’</li>
</ul></li>
<li>The fluorescent signal is acquired</li>
<li>3 bases at the 5’ of the probes are cleaved, removing the dye</li>
<li>Phosphatase is also used so to cap eventual unextended fragments</li>
<li>The step is repeated until needed by ligating another di-base probe at the 5’ of the previous one</li>
<li>Since each probe is 8 nucleotides long but 3 nucleotides are cleaved, the system interrogates 2 bases every 5 (2 interrogated and 3 no, then 2 interrogated and so on)</li>
<li>Everithing melted and repeated with different primers that have an offset of -1, -2 , -3, and -4 bases
<ul>
<li>In this way I get a reading for the missing positions</li>
<li>I get 2 reads from 2 different probes at each position</li>
</ul></li>
<li>There is an unique conbination of bases that can give the combination of reads, so I can reconstruct the original sequence
<ul>
<li>Each ordered combination of colors corresponds to a base</li>
</ul></li>
<li>It can produce more than 100 Gb per run!</li>
<li>Unfortunately read lenght is around 50-100 bp</li>
</ul>
<h2 id="complete-genomics">Complete genomics</h2>
<ul>
<li>It is used for re-sequencing common genomes</li>
<li>Fragments are made circular and then amplified by rolling circle amplification, obtaining DNA nanoballs (DNBs)</li>
<li>DNBTMs are around 200 nm in size</li>
<li>They are anchored in a chip obtained by photolitography</li>
<li>The chip is made so to have a grid pattern of sticky spots
<ul>
<li>A sticky spot is just a small well in the surface of the chip</li>
</ul></li>
<li>Each sticky spot recives exactly one nanoball, thanks to proprietary technology</li>
<li>Sequencing is done by combinatorial probe-anchor ligation (cPAL)</li>
<li>The DNB contains genomic DNA and an initial adapter sequence</li>
<li>1 of 4 labeled anchor probes made of a specific position and 8 aspecific positions binds to the adapter and it is ligated with ligase (similar to AB SOLiD)</li>
<li>Complete genomics was acquired by BGI and it does not sell sequencing equipment</li>
<li>You send samples to them and they produce data in ~100 days</li>
</ul>
<h2 id="pacbio">PacBio</h2>
<ul>
<li>It is really a promising technology</li>
<li>Reads are long, up to a 6-10 kb, but troughput is low</li>
<li>The long reads make assembly easy and don’t require really high depth of coverage</li>
<li>The error rate is quite high (15%), and probably it cannot be reduced under 5%</li>
<li>It is costly, 40k€ for 10x in mammalian genomes</li>
<li>It does not require amplification, so no bias is introduced</li>
<li>It is a golden standard for new sequencing projects, usually matched with Illumina
<ul>
<li>Assembling PacBio reads can be difficult due to the high error rate</li>
<li>Single Illumina reads are around 1% error, so assembling Illumina reads to PacBio reads is much easier</li>
<li>I can use PacBio to resolve repetitive regions and difficult-to-amplify regions, and Illumina for depth of coverage and accuracy</li>
</ul></li>
<li>PacBio was going to be bought by Illumina, but the anti-trust opposed it and themerger was canceled</li>
<li>It is based on Single Molecule Real Time (SMRT) Sequencing</li>
<li>Hairpin adapters are ligated to both ends of dsDNA, so to create a circular molecule</li>
<li>A sequencing primer and DNA polymerase are added and bind the DNA molecules, but do not extend it since nucleotides are not added</li>
<li>The DNA fragments with bound primer and polymerase are inserted in a SMRT cell</li>
<li>The SMRT cell contains millions of wells on its surface, called Zero-mode waveguides (ZMWs)</li>
<li>Each ZMW hosts a single DNA molecule with a single DNA polymerase and primer</li>
<li>The DNA polymerase is fixed at the botton of the ZMW, making the single-molecule signal detectable</li>
<li>Labeled nucleotides are added and their addition is detected in each ZMW
<ul>
<li>The systhesis is continuous, not stepwise like in Illumina</li>
<li>Detection is possible since the nucleotide pauses for some time at the bottom of the ZMW while it is added</li>
<li>AFter addition the dye is cleaved and diffuses away</li>
</ul></li>
<li>2 modes of operation are possible: Circular consensus Sequencing (CCS) and Continuous Long Reads (CLR)</li>
<li>In CCS the circular DNA is read again and again generating an high-fidelity (HiFi) read, with 99% accuracy</li>
<li>In CLR the molecule is as long as possible and it is read for as many nucleotides as possible, so to generate long reads</li>
<li>It is teoretically possible to detect modified bases with PacBio but this is not still done in practice
<ul>
<li>Modified bases tend to spend more time in the polymerase</li>
</ul></li>
</ul>
<h2 id="oxford-nanopore">Oxford nanopore</h2>
<ul>
<li>Long reads, but high error rate and low thorughput</li>
<li>The reads can potentially be very long, up to 100kb depending on library preparation</li>
<li>Libraries are prepared with double strand fragments in which are joined at one end by an hairpin adaptor</li>
<li>DNA passes trough a modified hemolysine pore altering the ion flow thorugh the pore
<ul>
<li>The pore is around 1 nm in diameter (half the widdht of DNA!)</li>
</ul></li>
<li>A motor protein pre-loaded on an adapter oligo regulates the speed at which DNA moves through the pore and acts as an helicase</li>
<li>After all the molecule has passed through the pore, since the adaptor is an hairpin the reverse strand is sequenced
<ul>
<li>In this way I have 2 reads per fragment</li>
</ul></li>
<li>Many DNA molecule pass in parallel through many nanopores (around 500 in MinION, 2000 in GridION) placed on a membrane</li>
<li>Each nanopore has its own sensor and it is placed in a nanowell</li>
<li>Bases are read in 4-mers and then the signal of subsequent reads is interpolated by a Recurrent Neural Network (RNN)</li>
<li>Interpretation of the raw data is difficult, because the meaning of reads depends on the sequence context
<ul>
<li>Error rate is around 4%</li>
<li>I can recognise not only ATCG, but also U, 5mC, and other modified bases</li>
<li>Machine learning!</li>
</ul></li>
<li>The platform is cheap (~5000€, sometimes given for free) but adapters and accessories are expensive</li>
<li>It is invaluable when I have to work on-site, since it is small and portable</li>
<li>MinION can produce 150 Mb per run with 48kb reads</li>
<li>Oxford Nanopore can be used not only for sequencing, but also for detecting protein-DNA interactions, small molecules</li>
</ul>
<h2 id="other-ngs-techniques">Other NGS techniques</h2>
<ul>
<li>Intelligent BioSystems Mini20 is a sequencing by synthesis platform designed for clinical use
<ul>
<li>It has 100 nt long reads, but it is expected to be able to compete with Sanger sequencing</li>
<li>It is sensitive to repeats</li>
<li>Full costs are still not clear, but the instrument costs 120k $ and the disposable flow cell 150 $</li>
</ul></li>
<li>Genia Technologies is an early stage announcment for a system that should combine Ion Torrent and Oxford Nanopore
<ul>
<li>It claims a sensitivity 1-2 orders of magnitude greater than Oxford Nanopore, with as many as 100k pores per chip, with as many as 100k pores per chip</li>
<li>Planned sample cost less than 100 $</li>
</ul></li>
</ul>
<h1 id="applications-of-ngs">Applications of NGS</h1>
<ul>
<li>A genome assembly can be done in chromosomes or in scaffolds</li>
<li>Scaffolds are assembled from contigs</li>
<li>Sometimes it is not possible to assemble entire chromosomes</li>
<li>The quality score of an assembly (n50) is the minimum size of scaffolds that contain 50% of the assembled genome</li>
<li>A human chromosome is on average 80-100 Mb</li>
<li>ChiPseq (chromatine immunoprecipitation) is a method used to analyse DNA-protein interactions
<ul>
<li>The output is a library of sequences that bind the protein of interest</li>
<li>The first step is to fix the proteins with DNA using formaldehyde</li>
<li>Subsequently, cells are lised and DNA fragmented</li>
<li>The sequences of interest are recovered with Ab against the protein of interest</li>
<li>I reverse the DNA-protein binding and sequence the fragments</li>
</ul></li>
<li>If I want to reduce cost, I can sequence only the exome
<ul>
<li>The exome is around 1% of the genome in humans!</li>
<li>In order to sequence the exome I need a capturing system</li>
<li>If not commercially available I have to evaluate if developping a capturing system is worth it</li>
<li>In order to enrich for the exome, I need to have specific probes that bind to exon regions, either in solution (on beads) or in microarrays</li>
<li>Probes are typically obtained from cDNA</li>
</ul></li>
<li>If I do not have enough money to sequence every individual, I can pool DNA samples in group (i.e. breed) and do a sequencing for each group</li>
<li>A reduced representation library is obtained by digestion of the genome
<ul>
<li>I run the digest on agarose and retrieve only a specific subset of MW</li>
<li>If I see definite bands in the gel, these probably come from repeated regions that are cut at the same lenght
<ul>
<li>I want to exclude this (!)</li>
</ul></li>
<li>In the digestion, I can choose a restriction enzyme with a long target sequence if I want longer fragments (cut site less probable!) and vice versa</li>
</ul></li>
<li>RNA-seq is an NGS application used for revealing the presence and quantity of RNA in a biological sample at a given moment
<ul>
<li>It can be used to asses alternative splicing events, post-trascriptional modifications</li>
<li>It can be used to identify exon-intron boundaries</li>
<li>In general, RNA is isolated and eventually enriched for the species of interest (mRNA, tRNA, …)
<ul>
<li>rRNA usually needs to be depleted since it represent 90% of the total rRNA content</li>
</ul></li>
<li>cDNA is synthesised from the RNA library, fragmented and size-selected
<ul>
<li>Biases can be introduced at this step</li>
<li>Direct RNA sequencing has been tried by several companies</li>
</ul></li>
</ul></li>
<li>NGS has several applications in cancer research
<ul>
<li>It can be used for detecting not only SNPs but also large indels, by looking at differential depth of coverage</li>
<li>I can detect cromosomal translocation by looking for reads that span 2 chromosomes</li>
<li>I can detect viruses and aother pathogen’s genomes</li>
</ul></li>
<li>A CNV is a 1 kb or longer DNA segment present at variable copy number</li>
<li>They can be discovered by analizing the depth of coverage of the region
<ul>
<li>This does not tell me in which allele the copies are (!)</li>
</ul></li>
<li>Array competitive genomic hybridization (aCGH) was once a golden standard for CNVs, now it is not
<ul>
<li>It is used for the identification of tumors</li>
<li>It is performed on a DNA microarray</li>
<li>Single probes are 50-75 nucleotides long and they are syntetized
<ul>
<li>They are selected so to be spaced around 20 kb apart and to have a specific GC content</li>
<li>I need to have a certain GC content so to be able to do the annealing step for all the microarray at the same temperature</li>
<li>I do not want probes on repeated sequences</li>
</ul></li>
<li>I do the hybridization with a reference DNA and the sample mixed and marked with different fluorophores</li>
<li>I measure the log_2 of the ratio of the intensities in order to call CNVs
<ul>
<li>0 means that I have the same number of copies, 1 that I have the double number of copies</li>
</ul></li>
<li>If I want to decrease the noise I can decide to call only more than 5 (es) sequential calls at the same level
<ul>
<li>In this way I loose resolution (!)</li>
</ul></li>
<li>Note that if I compare the X chromosome in males and females, I get double the reads in females (!)</li>
<li>It is a good complement for cytogenetics</li>
</ul></li>
<li>High density SNP arrays are the most common method used for CNV detection
<ul>
<li>CNV alters the signal intesity of certain probes due to the differential amount of DNA present</li>
<li>I can also detect a concerted pattern of intensity alteration in neighboring SNPs</li>
<li>Various algorithms are availabe for calling CNVs from SNP array data</li>
</ul></li>
<li>ATAC-seq (Assay for Transposase-Accessible Chromatin) uses a transposase to generate fragments in open chromatine regions, outside of nucleosomes</li>
<li>Bisulphite sequencing is used to detect methylated regions by converting C but not 5mC to T with bisulphite</li>
</ul>
<h1 id="plink">Plink</h1>
<ul>
<li>A pedigree is a standardised representation of individuals in a population and relationships among them
<ul>
<li>It can be represented in plane text or in binary form</li>
</ul></li>
<li>Plink is an important tool for working with reference genomes
<ul>
<li>It can work with text files (<code>--file</code> parameter, without extension for homonimous .ped and .map files)</li>
<li>It can work with binaries (<code>--bfile</code> option)</li>
</ul></li>
<li>PED and MAP file work in pairs: I typically have my_file.ped and my_file.map with the same root name and referring to the same data</li>
<li>The PED (pedigree) file is a text file with a row for each individual
<ul>
<li>It stores the pedigree of the population</li>
<li>This format is standard and it is used by different tools</li>
<li>It is Tab-separated and there are fields for the father, mother, sex, family, phenotype, SNPs</li>
<li>Missing data are usually reported with 0</li>
</ul></li>
<li>The MAP (map on the genome) file is a text file that has a line for each SNP
<ul>
<li>It reports chromosome number, SNP ID, position, distance from other SNPs</li>
<li>It is produced processing the raw output of a genotyping platform</li>
</ul></li>
<li>A polymorphism is such if it has a frequency higher than 1%</li>
<li>Before doing data analysis, check your data (!)
<ul>
<li>I want to exclude faulty individuals and faulty loci</li>
<li>Plink can filter out data at a given threshold</li>
<li>I want to exclude low-frequency alleles: my focus is the population, not the individual</li>
<li>I can exclude SNPs that violate the HW equilibrium</li>
<li>I can exclude mendelian errors: genotypes that are impossible given the parents</li>
</ul></li>
<li>Basic usage
<ul>
<li><code>--freq</code> gives the frequency of a SNP</li>
<li>If I don’t trust the data provider about the sexes, I can check for absolute homozigosity at X loci: in this case I have a male</li>
<li>I can want to filter out duplicates due to sampling errors</li>
<li>If I am working with non-human or I have partially assembled scaffolds, I need to specify <code>--allow-extra-chromosomes</code> or the species, if available in plink (es. <code>--sheep</code>)</li>
<li><code>--out</code> specifies the root filename of the output</li>
<li><code>--noweb</code> is usually required otherwise it checks forever for updates</li>
</ul></li>
</ul>
<h1 id="genome-assembly">Genome assembly</h1>
<ul>
<li>The main approaches for sequencing large repeat-rich genomes are whole genome shotgun and hierarchical shotgun (BAC based)
<ul>
<li>The human genome is repeat rich</li>
</ul></li>
<li>Hierarchical shotgun allows to resolve repetitive regions by dividing the genome in 100-200 kb chunks and sequencing these separately
<ul>
<li>This makes long-range assembly errors unlikely and it reduces the incidence of short-range errors</li>
<li>The single chunks are then sequenced by shotgun</li>
</ul></li>
<li>It is possible that some of these chunks suffer rearrangement in the library preparation process</li>
<li>At the time of the first human genome, sequencing was expensive so we could not sequence BACs and then assemble them, we needed to select non-duplicate BACs beforehand</li>
<li>I start from a gene in a known position in a chromosome, and check which BACs contain it by PCR
<ul>
<li>This links my assembly to the physical chromosome</li>
</ul></li>
<li>Reads are assembled in contigs, which are joined in scaffolds</li>
<li>At the scaffold level I can now the gap size among scaffolds thanks to paired reads</li>
<li>Genetic maps are linkage maps, and they can be used for assembling genomes</li>
<li>Physical maps refer to the position of a gene in the chromosome</li>
<li>A strategy to select overlapping BACs is to digest them with restriction enzymes and search for common fragments among different BACs</li>
<li>The main problems of hierarchical shotgun are that it is slow and assembly is problematic if some BACs contain chimeric DNA
<ul>
<li>Chimeric DNA is a fragment that is created by the association of fragments from different chromosomes during the construction of the library</li>
</ul></li>
<li>N50 is a statistics that defines assembly quality in terms of contiguity
<ul>
<li>It is the lenght of the sorterst contig that allows to surpass 50% coverage of the genome</li>
</ul></li>
<li>The state of the art is to do a first PacBio sequencing to get a rough map to which I can attach subsequent precise Illumina paired-end reads
<ul>
<li>I want to use more than one Illumina run, with different lengths, so to discriminate repetitive regions and to correct errors in the PacBio phase</li>
</ul></li>
<li>Radiation hybrid maps now can be used for refining an assembly
<ul>
<li>I form an hybridome between an immortalized cell from a different species and a normal cell from the organism that I want to sequence</li>
<li>The hybrid will lose most of the genome of the normal cell, and it will retain a random fragment</li>
<li>In this way I can get a library (!)</li>
<li>The evaluation of the retained fragment is done by cariotyping thanks to banding patterns</li>
<li>I can then test by PCR to locate specific tags</li>
<li>By cross-referencing caryotype and PCR I can get a rough map of in which chromosome genes are (not so useful now, used in the pre-sequencing era)</li>
<li>If before the formation of the hybrid I irradiate the normal line, I break its DNA and get small fragments</li>
<li>In this case I want to have a very big library, where each clone has a small fragment</li>
<li>I can test by PCR in order to understand which markers from which chromosomes I get from each clone</li>
<li>If in my assembly I have a contig that I cannot locate, I design PCR primers for that region</li>
<li>I test all the library with the primers, and I select the clones that contain my tag</li>
<li>I check those clones for other markers of known position, and I check the ones that are more frequently associated with the tag of unknown position</li>
<li>In this way, I can say that the unallocated contig is physically linked to a tag of known position</li>
<li>The distance from between tags defined in this way is defined in cRay</li>
</ul></li>
</ul>
<h1 id="study-of-genomes">Study of genomes</h1>
<h2 id="linkage-disequilibrium">Linkage disequilibrium</h2>
<ul>
<li>Linkage disequilibrium (LD) is the nonrandom association of alleles at different loci</li>
<li>I can define the LD coefficient  <img class="inlinemath" src="eqn003.png" WIDTH=34 HEIGHT=17 STYLE="vertical-align: -4px; margin: 0;" alt="D_{AB}" /> as the difference among the frequency of gametes carrying the combination of alleles AB, and the product of the independent frequencies of gametes with alleles A and B  <img class="displaymath" src="eqn004.png" WIDTH=155 HEIGHT=19 STYLE="vertical-align: -5px; margin: 0;" alt=" D_{AB} = p_{AB} - p_A*p_B " /></li><li>If  <img class="inlinemath" src="eqn005.png" WIDTH=46 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="D=0" /> I am in linkage equilibrium (LE): the fequency of occurence of the AB aplotype is that expected from allele frequencies</li><li> <img class="inlinemath" src="eqn006.png" WIDTH=16 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="D" /> decreases in generations at a rate that depends on the frequency of recombination among the 2 loci  <img class="displaymath" src="eqn007.png" WIDTH=217 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt=" D_{AB}(t+1) = (1-c)*D_{AB}(t)" /></li><li>LE will always be reached, albeit usually really slowly
<ul>
<li>Even in loci in unlinked loci,  <img class="inlinemath" src="eqn006.png" WIDTH=16 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="D" /> only halves each generation</li></ul></li>
<li>The normalised version of  <img class="inlinemath" src="eqn006.png" WIDTH=16 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="D" />, called  <img class="inlinemath" src="eqn008.png" WIDTH=20 HEIGHT=16 STYLE="vertical-align: -1px; margin: 0;" alt="D'" />, is the ration with its maximum possible value  <img class="displaymath" src="eqn009.png" WIDTH=101 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt=" D' = D/D_{max}" /></li><li>Another often used metric is  <img class="inlinemath" src="eqn010.png" WIDTH=16 HEIGHT=17 STYLE="vertical-align: -1px; margin: 0;" alt="r^2" />, which is related to  <img class="inlinemath" src="eqn006.png" WIDTH=16 HEIGHT=14 STYLE="vertical-align: -1px; margin: 0;" alt="D" /> and is the correlation coefficient of the 2*2 genotype matrix  <img class="displaymath" src="eqn011.png" WIDTH=210 HEIGHT=44 STYLE="vertical-align: -17px; margin: 0;" alt="r^2 = \frac{D^2}{p_A(1- p_A)*p_B(1-p_B)}" /></li><li>We can detect crossing-over by looking for the association of genetic markers</li>
<li>An aplotype is a cluster of genes that are usually eredited toghether</li>
<li>The probability of CO between 2 genes is measured in cM
<ul>
<li>1 cM is a genetic distance such that in 100 meiosis I expect 1 CO</li>
<li>It is around  <img class="inlinemath" src="eqn012.png" WIDTH=24 HEIGHT=17 STYLE="vertical-align: -1px; margin: 0;" alt="10^6" /> nucleotides for mammals</li></ul></li>
<li>If I have a simple dominant trait, I am certain only about the allele frequency of the recessive
<ul>
<li>I can recover it by  <img class="inlinemath" src="eqn013.png" WIDTH=295 HEIGHT=20 STYLE="vertical-align: -4px; margin: 0;" alt="recessive\ allele = \sqrt{recessive\ phenotype}" /></li><li>Doing this, I am assuming that the population is infinite, there is no mutation, no selection, no genetic drift, no migration, random mating</li>
</ul></li>
<li>If the observed genotype frequencies are different from the ones expected from HW equilibrium, It means that there are factors at play that perturbate the equilibrium
<ul>
<li>There can also be genotyping problems (my region is difficult to sequence and I do not get the right sequence)</li>
</ul></li>
<li>Two loci are in linkage disequilibrium if they do not occur randomly with respect to each other</li>
<li>Aplotypes are patterns of genetic variation in populations</li>
<li>The genotype is not sufficient for predicting the aplotypes
<ul>
<li>I cannot differentiate if a variation is in one chromosome or the other (!)</li>
<li>We need information on aplotype frequencies or on the parents</li>
</ul></li>
<li>PHASE is a website for analyzing aplotypes</li>
<li>I cannot determine the aplotype by only looking at the genotype: I need data on the population</li>
<li>In human the average linkage disequilibrium is low, around 1kb</li>
<li>When effective population size is low, likage disequilibrium is large
<ul>
<li>This is true for lifestock</li>
</ul></li>
<li>In DNA sequencing chips, I detect a series of SNPs distanced about the linkage disequilibrium
<ul>
<li>If 2 SNPs are close enough, I can infer that the sequence in between is what I would expect from the aplotype</li>
</ul></li>
</ul>
<h2 id="signatures-of-selection">Signatures of selection</h2>
<ul>
<li>A selective sweep is the reduction or elimination of variation among the nucleotides in neighboring DNA of a mutation as the result of recent and strong positive natural or artificial selection
<ul>
<li>The DNA sequence is analysed in a 40 kbp sliding window in pooled sequence data</li>
<li>The number of reads corresponding to the 2 alleales is evaluated for each SNP
<ul>
<li>I count the number of reads with the major allele ( <img class="inlinemath" src="eqn014.png" WIDTH=41 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="n_{MAJ}" />) and with the minor allele ( <img class="inlinemath" src="eqn015.png" WIDTH=41 HEIGHT=13 STYLE="vertical-align: -4px; margin: 0;" alt="n_{MIN}" />)</li></ul></li>
<li>This leads to estimating an heterozygosity score for each window position for each pool  <img class="displaymath" src="eqn016.png" WIDTH=381 HEIGHT=30 STYLE="vertical-align: -10px; margin: 0;" alt=" H_p = 2 \sum n_{MAJ} * \sum n_{MIN} / (\sum n_{MAJ} + \sum n_{MIN})^2" /> <ul>
<li> <img class="inlinemath" src="eqn017.png" WIDTH=64 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="\sum n_{MAJ}" /> and  <img class="inlinemath" src="eqn018.png" WIDTH=64 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="\sum n_{MIN}" /> are respectively the sums of the number of reads for each category for all the SNPs in the window</li><li>If I have an homozigous region all the SNPs there will have their major allele more frequent!</li>
<li> <img class="inlinemath" src="eqn019.png" WIDTH=51 HEIGHT=19 STYLE="vertical-align: -5px; margin: 0;" alt="H_p=1" /> is when the 2 alleles have equal frequency ( <img class="inlinemath" src="eqn020.png" WIDTH=145 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="\sum n_{MAJ} = \sum n_{MIN}" />)</li><li> <img class="inlinemath" src="eqn021.png" WIDTH=52 HEIGHT=19 STYLE="vertical-align: -5px; margin: 0;" alt="H_p=0" /> when  <img class="inlinemath" src="eqn022.png" WIDTH=95 HEIGHT=20 STYLE="vertical-align: -5px; margin: 0;" alt="\sum n_{MIN}=0" /></li></ul></li>
<li>The  <img class="inlinemath" src="eqn023.png" WIDTH=22 HEIGHT=19 STYLE="vertical-align: -5px; margin: 0;" alt="H_p" /> value is then normalized as  <img class="displaymath" src="eqn024.png" WIDTH=163 HEIGHT=21 STYLE="vertical-align: -6px; margin: 0;" alt=" Z_{H_p} = (H_p-\mu_{H_p})/\sigma_{H_p}" /></li><li>I can set a  <img class="inlinemath" src="eqn025.png" WIDTH=29 HEIGHT=20 STYLE="vertical-align: -7px; margin: 0;" alt="Z_{H_p}" /> threshold and call a selective sweep when the threshold is passed for a window position</li><li>Data is usually presented with a Manhattan plot with th  <img class="inlinemath" src="eqn025.png" WIDTH=29 HEIGHT=20 STYLE="vertical-align: -7px; margin: 0;" alt="Z_{H_p}" /> score of each window position plotted along the genome axis<ul>
<li>Colors are used to distinguish where a cromosome ends and another start</li>
</ul></li>
</ul></li>
</ul>
<h2 id="quantitative-trait-loci-qtls">Quantitative trait loci (QTLs)</h2>
<ul>
<li>A quantitative trait locus (QTL) is a locus (section of DNA) that correlates with variation of a quantitative trait in the phenotype of a population of organisms</li>
<li>They are mapped by identifying which molecular markers are correlated to the observed phenotype</li>
<li>Expression quantitative trait loci (eQTLs) are genomic loci that explain variation in expression levels of mRNAs</li>
</ul>
<h2 id="genotyping">Genotyping</h2>
<ul>
<li>Genotyping means to determine the genotype at one locus</li>
<li>I can perform high throughput genotyping with beadchips
<ul>
<li>I have beads with primers that anneal in different positions in the genome, so to be evenly spaced and below the linkage disequilibrium lenght</li>
<li>The output of a beadchip is essentially a .map file with additional experimental information (signal intensity for the SNP)</li>
<li>The position of some probes in the genome is unknown, so the row of their SNP starts with 0 (chromosome) and ends with 0 (position)</li>
</ul></li>
<li>The main genotyping platforms are from Illumina and Affimetrix</li>
<li>The probe is designed so to
<ul>
<li>Bind to a unique region (it has to be long enough!)</li>
<li>It has to have standard GC content, so I can melt all the chip at the same temperature</li>
</ul></li>
<li>The specific fragments to be genotyped are detected by primer extension
<ul>
<li>I have a primer right in front of a SNP</li>
<li>I add the 2 possible nucleotides for the SNP labeled with different fluorophores and blocked</li>
<li>I see what happens</li>
</ul></li>
<li>The minor allele frequency (MAF) is the frequency of the rarer variant of a SNP
<ul>
<li>It can go from 0 to 0.5</li>
</ul></li>
<li>I do not need to genotype all the SNPs
<ul>
<li>I can take advantage of linkage disequilibrium to detect aplotypes</li>
<li>Polimorphic sites are more informative than sites with rare variants, so I tend to focus on them for determining an aplotype</li>
</ul></li>
<li>Genotyping by sequencing (GBS) allows to detect unknown SNPs and it is typically done with pooled reduced representation libraries</li>
<li>Illumina can produce customized genotyping chips</li>
</ul>
<h2 id="gwas">GWAS</h2>
<ul>
<li>I want to find the association between a phenotype and a genomic locus</li>
<li>I can genotype individuals with a SNPs array and see if there is association with the phenotype
<ul>
<li>I check allele frequencies that differ in the different cohorts</li>
</ul></li>
<li>The result is a Manhattan plot
<ul>
<li>I have the chromosome lenght on the x axis (coordinate of the SNPs)</li>
<li>In the y axis I have the -log of the p-value for the association
<ul>
<li>Lower p-values are on the highest part (!)</li>
</ul></li>
</ul></li>
<li>I am doing a lot of multiple testing so my threshold must be really high (!)
<ul>
<li>I use the Bonferroni correction or false discovery rate</li>
</ul></li>
<li>Continuous traits tend to be normally distributed
<ul>
<li>On a SNPs A/G I can have 3 possible genotypes: AA, AG, GG</li>
<li>I measure the genotype of each individual and its continuous trait</li>
<li>I take the means of the groups for each genotype and I perform a statistical test on means, like ANOVA</li>
</ul></li>
<li>In order to maximize the differences between pools, I can take samples from the extreme ends of the phenotype distribution
<ul>
<li>This is called extreme phenotype study</li>
</ul></li>
</ul>
<h2 id="runs-of-homozigosity">Runs of Homozigosity</h2>
<ul>
<li>The inbreeding coefficient indicates the probability that random positions among 2 individuals are equal by descent
<ul>
<li>It is calculated by tracing a close path on the pedigree of an individual</li>
</ul></li>
<li>Runs of homozigosity (ROH) refer to stretches of chromosome which are completely homozygus
<ul>
<li>This could mean that the 2 stretches are identical by descent (!)</li>
<li>The ROH % is equivalent to the coefficient of inbreeding</li>
</ul></li>
</ul>
<h1 id="selected-papers">Selected papers</h1>
<h2 id="strong-signatures-of-selection-in-the-domestic-pig-genome---rubin-et-al.-2012">Strong signatures of selection in the domestic pig genome - Rubin et al. 2012</h2>
<ul>
<li>Selective sweep showed selection signature in QTLs related to elongation of the back and number of vertebrae
<ul>
<li>Wild boars have 19 vertebrae, domestic pigs 21-23</li>
</ul></li>
<li>The domestic pig evolved from several divergent subspecies of wild boar</li>
<li>They used WGS on the draft pig genome assembly for udentifying loci under seleciton since pig domestication</li>
<li>They looked for allele frequency differences among wild boar and pig populations</li>
<li>2 different datasets
<ul>
<li>Mate pair reads from 8 pools of pigs and wild boars at 5x depth per pool</li>
<li>Paired-end reads from 37 individual pigs and 11 wild boars at 10x coverage each</li>
</ul></li>
<li>Identified an homoziguous region in the X chromosome, that is however present also in wild boars</li>
<li>Selective sweep at the melanocortin 4 receptor locus, related to food intake</li>
<li>Selective sweep at the NR6A1 locus, related to the number of vertebrae</li>
<li>Selective sweep candidates at PLAG1, LCORL, related to body lenght
<ul>
<li>They are related to height also in humans</li>
</ul></li>
<li>Selective sweep at OSTN, related to the type of muscle and bone development</li>
<li>Observed excess of non-synonimous substitutions in derived mutations in domestic pig and scarcity of non-sense mutations</li>
<li>8 kb duplication in a CASP10 intron in domestic pigs</li>
<li>Structural variants at the KIT locus related to white spotting</li>
</ul>
<h2 id="high-throughput-snp-discovery-in-the-rabbit-oryctolagus-cuniculus-genome-by-next-generation-semiconductor-based-sequencing---fontanesi-et-al.-2014">High-throughput SNP discovery in the rabbit (<em>Oryctolagus cuniculus</em>) genome by next-generation semiconductor-based sequencing - Fontanesi et al. 2014</h2>
<ul>
<li>Sequenced 2 RRLs for SNP discovery using IonTorrent Personal Genome Machine</li>
<li>Genomic DNA of 10 rabbits from different breeds pooled and digested separately with HaeIII and RsaI</li>
<li>Sequenced 280 Mb from the first RRL and 417 Mb from the second</li>
<li>Reads combined covered 15.82% of the rabbit genome</li>
<li>62k SNPs were called</li>
<li>Some SNPs were validate by Sanger</li>
</ul>
<h2 id="design-of-a-high-density-snp-genotyping-assay-in-the-pig-using-snps-identified-and-characterized-by-next-generation-sequencing-technology---ramos-et-al.-2009">Design of a High Density SNP Genotyping Assay in the Pig Using SNPs Identified and Characterized by Next Generation Sequencing Technology - Ramos et al. 2009</h2>
<ul>
<li>19 RRLs derived from 4 pig breeds and a wild boar population, using AluI, HaeIII and MspI</li>
<li>Sequencing with Illumina with 36 nt reads</li>
<li>Identified more than 372k SNPs</li>
<li>These and other SNPs (549k in total) were used for designing the Illumina Porcine 60k+ SNP beadchip, which included 64k SNPs</li>
</ul>
<h2 id="whole-genome-resequencing-reveals-loci-under-selection-during-chicken-domestication---rubin-et-al.-2010">Whole-genome resequencing reveals loci under selection during chicken domestication - Rubin et al. 2010</h2>
<ul>
<li>44.5x coverage of the chicken genome using pooled DNA from 8 chicken populations and a red jungle fowl population (major wild ancestor)</li>
<li>Sequencing with SOLiD</li>
<li>They distinguished broilers and layers populations</li>
<li>Reported 7M SNPs, 1300 deletions, and some selective sweeps</li>
<li>Selective sweep in all the domestic population at the TSHR locus (metabolic regulation and photoperiod control of reproduction)</li>
<li>Selective sweeps in broilers associated with growth, appetite and metabolic regulation</li>
<li>No much evidence of loss-of-function mutations in chicken evolution</li>
</ul>
<h1 id="examination-mode">Examination mode</h1>
<ul>
<li>Final exam has 2 levels
<ul>
<li>Preparation of a genomic project
<ul>
<li>A text should be written including an appropriate introduction to the problem/question that the experiment or project would like to analyse or answer, aim of the project, a section with materials and methods, expected results and impact</li>
<li>The project should be submitted to the professor one week before the interview</li>
<li>We should specify what is the aim of the project and what I’d like to solve with it
<ul>
<li>If it makes sense, we can undergo a discussion with him</li>
</ul></li>
<li>The project is based on money: we’ll have a budget</li>
</ul></li>
<li>Interview based on the project submitted and other two questions
<ul>
<li>Only students that are positively evaluated at the first level are admitted at the second level</li>
<li>Evaluation of basic knowledge</li>
</ul></li>
</ul></li>
<li>We get one extra point if we pass at the first attempt</li>
<li>It is important to follow him</li>
<li>We’ll have an example of a project, the topic of the project it’s up to us</li>
<li>We need to choose a complex genome/organism</li>
<li>Each one will have a different budget</li>
<li>It’s better to do the project according to what we discuss in the lectures</li>
<li>It has to be something new</li>
<li>The first date would be in February after Winter School and another one in March</li>
<li>Near to the end of the course we’ll have a test with 30 questions to test our level (it won’t count for the final score)</li>
</ul>
